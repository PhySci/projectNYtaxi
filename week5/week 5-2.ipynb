{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frodos/anaconda/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn import preprocessing, linear_model, model_selection\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "import statsmodels.api as sm\n",
    "from itertools import product\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс моделей ARIMA недостаточно богат для наших данных: с их помощью, например, никак нельзя учесть взаимосвязи между рядами. Это можно сделать с помощью векторной авторегрессии VARIMA, но её питоновская реализация не позволяет использовать регрессионные признаки. Кроме того, авторегрессионный подход не позволяет учитывать, например, взаимодействия между сезонными компонентами. Вы могли заметить, что форма суточных сезонных профилей в будни и выходные немного разная; явно моделировать этот эффект с помощью ARIMA не получится.\n",
    "\n",
    "Нам нужна более сложная модель. Давайте займёмся сведением задачи массового прогнозирования рядов к регрессионной постановке! Вам понадобится много признаков. Некоторые из них у вас уже есть — это:\n",
    "<ol>\n",
    "<li>идентификатор географической зоны\n",
    "<li>дата и время\n",
    "<li>количество поездок в периоды, предшествующие прогнозируемому\n",
    "<li>синусы, косинусы и тренды, которые вы использовали внутри регрессионной компоненты ARIMA\n",
    "<li>Кроме того, не спешите выбрасывать построенный вами на прошлой неделе прогнозы — из них может получиться хороший признак для регрессии!\n",
    "</ol>\n",
    "\n",
    "\n",
    "\n",
    "Вы можете попробовать разные регрессионный модели, но хорошие результаты, скорее всего, дадут такие, которые будут позволять признакам взаимодействовать друг с другом.\n",
    "\n",
    "Поскольку прогноз нужен на 6 часов вперёд, проще всего будет построить 6 независимых регрессионных моделей — одна для прогнозирования y^T+1|T, другая для y^T+2|T и т.д.\n",
    "\n",
    "<ol>Чтобы сдать задание, выполните следующую последовательность действий.\n",
    "<li>Для каждой из шести задач прогнозирования y^T+i|T,i=1,…,6 сформируйте выборки. Откликом будет yT+i при всевозможных значениях T, а признаки можно использовать следующие:\n",
    "<ul>\n",
    "<li>идентификатор географической зоны — категориальный\n",
    "<li>год, месяц, день месяца, день недели, час — эти признаки можно пробовать брать и категориальными, и непрерывными, можно даже и так, и так (done)\n",
    "<li>синусы, косинусы и тренды, которые вы использовали внутри регрессионной компоненты ARIMA (done)\n",
    "<li>сами значения прогнозов ARIMA y^T+i|TARIMA\n",
    "<li>количество поездок из рассматриваемого района в моменты времени yT,yT−1,…,yT−K (параметр K можно подбирать; попробуйте начать, например, с 6)\n",
    "<li>количество поездок из рассматриваемого района в моменты времени yT−24,yT−48,…,yT−24∗Kd (параметр Kd можно подбирать; попробуйте начать, например, с 2)\n",
    "<li>суммарное количество поездок из рассматриваемого района за предшествующие полдня, сутки, неделю, месяц\n",
    "</ul>\n",
    "Будьте внимательны при создании признаков — все факторы должны быть рассчитаны без использования информации из будущего: при прогнозировании y^T+i|T,i=1,…,6 вы можете учитывать только значения y до момента времени T включительно.\n",
    "\n",
    "\n",
    "<li>Выбранными моделями постройте для каждой географической зоны и каждого конца истории от 2016.04.30 23:00 до 2016.05.31 17:00 прогнозы на 6 часов вперёд; посчитайте в ноутбуке ошибку прогноза по следующему функционалу:\n",
    "Qmay=1R∗739∗6∑r=1R∑T=2016.04.3023:002016.05.3117:00∑i=16y^T|T+ir−yT+ir.\n",
    "Убедитесь, что ошибка полученных прогнозов, рассчитанная согласно функционалу Q, определённому на прошлой неделе, уменьшилась по сравнению с той, которую вы получили методом индивидуального применения моделей ARIMA. Если этого не произошло, попробуйте улучшить ваши модели.\n",
    "\n",
    "<li>Итоговыми моделями постройте прогнозы для каждого конца истории от 2016.05.31 23:00 до 2016.06.30 17:00 и запишите все результаты в один файл в формате geoID, histEndDay, histEndHour, step, y. Здесь geoID — идентификатор зоны, histEndDay — день конца истории в формате id,y, где столбец id состоит из склеенных через подчёркивание идентификатора географической зоны, даты конца истории, часа конца истории и номера отсчёта, на который делается предсказание (1-6); столбец y — ваш прогноз.\n",
    "\n",
    "<li>Загрузите полученный файл на kaggle: https://inclass.kaggle.com/c/yellowtaxi. Добавьте в ноутбук ссылку на сабмишн.\n",
    "\n",
    "<li>Загрузите ноутбук в форму."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# id нужных регионов\n",
    "regsDf = pd.read_csv('../crowdRegs.csv',names=['id','regId']);  \n",
    "\n",
    "# времянные ряды для этих регионов\n",
    "df = pd.read_pickle('../loadData/crowdRegs3.pcl')\n",
    "regNames = regsDf.regId.values.astype('str')\n",
    "df.columns = regNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наверное, оптимальный способ - пройтись по всем регионам, сформировать требуемую выборку, а потом - состыковать. \n",
    "Вероятно, в процессе работы получится векторизовать это действие.\n",
    "Пожалуй, имеет смысл сначала для всего фрейма добавить общие для всех колонок признаки (тренд, гармоники, даты, дни недели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def processDataFrame(inpDf, Kw = 5, Ka = 2):\n",
    "    \"\"\"\n",
    "    Обрабатываем сразу весь dateFrame и добавляем признаки, общие для всех рядов\n",
    "    тренд, гармоники, категориальные перемнные\n",
    "    для дат, дней недели, etc)\n",
    "\n",
    "    Parameters:\n",
    "    Kw number of weeks harmonics\n",
    "    Ka number of annual harmonics\n",
    "    \"\"\"\n",
    "\n",
    "    inpDf = inpDf.assign(linear = (inpDf.index - datetime.datetime(2014,1,1,0,0,0))/np.timedelta64(1, 'h'))\n",
    "    \n",
    "    # час — эти признаки можно пробовать брать и категориальными\n",
    "    # и непрерывными, можно даже и так, и так\n",
    "\n",
    "    # добавляем гармонические фичи\n",
    "    for ind in range(1,Kw+1):\n",
    "        inpDf['weekCos'+str(ind)]= np.cos(np.pi*inpDf.linear*ind/168)\n",
    "        inpDf['weekSin'+str(ind)]= np.sin(np.pi*inpDf.linear*ind/168)\n",
    "     \n",
    "    for ind in range(1,Ka+1):\n",
    "        inpDf['yearCos'+str(ind)]= np.cos(2*np.pi*inpDf.linear*ind/8766)        \n",
    "        inpDf['yearSin'+str(ind)]= np.sin(2*np.pi*inpDf.linear*ind/8766)\n",
    "\n",
    "    # добавляем числовое и категориальные свойства для дней недели\n",
    "    inpDf = inpDf.assign(dayOfWeek = inpDf.index.dayofweek)\n",
    "    lbDays = preprocessing.LabelBinarizer()\n",
    "    lbDays.fit(list(np.arange(6)))\n",
    "    DoW = pd.DataFrame(lbDays.transform(inpDf.index.dayofweek),columns = ['dayOfWeek_'+str(x) for x in np.arange(6)],\n",
    "                       index = inpDf.index)      \n",
    "    inpDf = inpDf.merge(DoW,left_index=True,right_index=True)\n",
    "\n",
    "    # добавляем dummy variables для месяца\n",
    "    inpDf = inpDf.assign(month = inpDf.index.month)\n",
    "    lbMonths = preprocessing.LabelBinarizer()\n",
    "    lbMonths.fit(list(np.arange(12)))\n",
    "    Months = pd.DataFrame(lbMonths.transform(inpDf.index.month),columns = ['month_'+str(x) for x in np.arange(1,13)],\n",
    "                          index = inpDf.index)      \n",
    "    inpDf = inpDf.merge(Months,left_index=True,right_index=True);\n",
    "\n",
    "    # добавляем год (вещественный)\n",
    "    inpDf = inpDf.assign(year = inpDf.index.year)\n",
    "\n",
    "    # добавляем день месяца (вещественный)\n",
    "    inpDf = inpDf.assign(day = inpDf.index.day)\n",
    "\n",
    "    # добавляем час (вещественный и категориальный)\n",
    "    inpDf = inpDf.assign(hour = inpDf.index.hour)\n",
    "    lbHours = preprocessing.LabelBinarizer()\n",
    "    lbHours.fit(list(np.arange(24)))\n",
    "    Hours = pd.DataFrame(lbHours.transform(inpDf.index.hour),columns = ['hour_'+str(x) for x in np.arange(24)],\n",
    "                       index = inpDf.index)      \n",
    "    inpDf = inpDf.merge(Hours,left_index=True,right_index=True)\n",
    "    \n",
    "    return inpDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь делаем индивидуальную обработку для каждого региона\n",
    "<ol>\n",
    "<li> добавляем идентификатор географической зоны — категориальный\n",
    "<li> количество поездок из рассматриваемого района в моменты времени yT,yT−1,…,yT−K (параметр K можно подбирать; попробуйте начать, например, с 6)\n",
    "<li> количество поездок из рассматриваемого района в моменты времени yT−24,yT−48,…,yT−24∗Kd (параметр Kd можно подбирать; попробуйте начать, например, с 2)\n",
    "<li>суммарное количество поездок из рассматриваемого района за предшествующие полдня, сутки, неделю, месяц \n",
    "2) \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def processSeries(df,tReg,Kh = 6, Kp = 2):\n",
    "    \"\"\"\n",
    "    Обработка одного данного ряда \n",
    "    parameters:\n",
    "        df - начальный датафрейм, из которого выберем для обработки один ряд\n",
    "        tReg - название ряда, который надо обработать\n",
    "        Kh - количество отслеживаемых прошлых суточных лагов \"назад\"\n",
    "        Kp - количество отслеживаемых прошлых периодических лагов (период 24 часа)\n",
    "\n",
    "    \"\"\"\n",
    " \n",
    "\n",
    "    tDf = df.loc[:,tReg.split() + commonFeatures].rename(columns={tReg:'y'})\n",
    "\n",
    "    tDf = tDf.assign(region = tReg)\n",
    "\n",
    "    for timeLag in np.arange(1,Kh+1):\n",
    "        name = 'hourLag_'+str(timeLag)\n",
    "        tDf.loc[:,name] = tDf.y.shift(periods=timeLag)\n",
    "\n",
    "    for timeLag in np.arange(1,Kp+1):\n",
    "        name = 'periodicLag_'+str(timeLag)\n",
    "        tDf.loc[:,name] = tDf.y.shift(periods=timeLag*24)\n",
    "\n",
    "    tDf.fillna(0,inplace=True)    \n",
    "\n",
    "    # суммарное количество поездок из рассматриваемого района за предшествующие полдня, сутки, неделю, месяц\n",
    "    tDf.loc[:,'sum12'] = tDf.y.rolling(window = 12, min_periods = 1).sum()\n",
    "    tDf.loc[:,'sum24'] = tDf.y.rolling(window = 24, min_periods = 1).sum()\n",
    "    tDf.loc[:,'sumWeek'] = tDf.y.rolling(window = 168, min_periods = 1).sum()\n",
    "    tDf.loc[:,'sumMonth'] = tDf.y.rolling(window = 720, min_periods = 1).sum()\n",
    "    \n",
    "    #создаём шесть целевые переменных для каждого конца истории\n",
    "    for targetVar in np.arange(1,7):\n",
    "        name = 'y'+str(targetVar)\n",
    "        tDf.loc[:,name] = tDf.y.shift(-targetVar)\n",
    "    tDf.fillna(0,inplace=True)\n",
    "    \n",
    "    return tDf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTrips(X):\n",
    "    model1 = bestModels.get('y1')\n",
    "    model2 = bestModels.get('y2')\n",
    "    model3 = bestModels.get('y3')\n",
    "    model4 = bestModels.get('y4')\n",
    "    model5 = bestModels.get('y5')\n",
    "    model6 = bestModels.get('y6')\n",
    "    pr1 = model1.predict(X)\n",
    "    pr2 = model2.predict(X)\n",
    "    pr3 = model3.predict(X)\n",
    "    pr4 = model4.predict(X)\n",
    "    pr5 = model5.predict(X)\n",
    "    pr6 = model6.predict(X)\n",
    "    pr1[pr1<0] = 0\n",
    "    pr2[pr2<0] = 0\n",
    "    pr3[pr3<0] = 0\n",
    "    pr4[pr4<0] = 0\n",
    "    pr5[pr5<0] = 0\n",
    "    pr6[pr6<0] = 0\n",
    "    \n",
    "    return np.array([pr1, pr2, pr3, pr4, pr5, pr6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def saveResults(rdf, fName):\n",
    "    rnd = np.round\n",
    "\n",
    "    f = open(fName,'w')\n",
    "    f.writelines('id,y\\n')\n",
    "\n",
    "    for ind, row in rdf.iterrows():\n",
    "        historyStart = row.date - datetime.timedelta(hours = 1)\n",
    "\n",
    "        if historyStart > datetime.datetime(2016,6,30,17):\n",
    "            continue\n",
    "\n",
    "        s0 = str(row.region)+'_'+ str(datetime.datetime.strftime(historyStart, \"%Y-%m-%d\"))+ '_'+ str(historyStart.hour)\n",
    "\n",
    "        s1 = s0 +'_1,'+str(rnd(row.get('y1'))) + '\\n'\n",
    "        f.writelines(s1)\n",
    "\n",
    "        s2 = s0 +'_2,'+str(rnd(row.get('y2'))) + '\\n'\n",
    "        f.writelines(s2)\n",
    "\n",
    "        s3 = s0 +'_3,'+str(rnd(row.get('y3'))) + '\\n'\n",
    "        f.writelines(s3)\n",
    "\n",
    "        s4 = s0 +'_4,'+str(rnd(row.get('y4'))) + '\\n'\n",
    "        f.writelines(s4)\n",
    "\n",
    "        s5 = s0 +'_5,'+str(rnd(row.get('y5'))) + '\\n'\n",
    "        f.writelines(s5)\n",
    "\n",
    "        s6 = s0 +'_6,'+str(rnd(row.get('y6'))) + '\\n'\n",
    "        f.writelines(s6)\n",
    "\n",
    "    f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# общая обработка данных\n",
    "df2 = processDataFrame(df,Kw = 7, Ka = 2)\n",
    "commonFeatures =  list(set(df2.columns)-set(df.columns.values))\n",
    "# обработка отдельных рядов\n",
    "df3 = pd.DataFrame()\n",
    "for regName in regNames:\n",
    "    df3 = pd.concat([df3, processSeries(df2,regName,Kh = 12, Kp = 4)])\n",
    "\n",
    "regDf = df3.get('region')\n",
    "df3 = pd.get_dummies(df3,'region')\n",
    "df3 = df3.assign(region = regDf)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3.to_pickle('df3.pcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_pickle('df3.pcl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте каждую из шести выборок на три части:\n",
    "<ul>\n",
    "<li> Обучающая, на которой будут настраиваться параметры моделей — всё до апреля 2016\n",
    "<li> Тестовая, на которой вы будете подбирать значения гиперпараметров — май 2016\n",
    "<li> Итоговая, которая не будет использоваться при настройке моделей вообще — июнь 2016\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь надо обучить регрессор на колонке y, откинув y1-y6\n",
    "\n",
    "Для повторяемости стоит зафиксировать random_state \n",
    "\n",
    "Попробовать AdaBoost Regressor над деревьями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "startTrain = '2014-01-01 00:00:00'\n",
    "endTrain   = '2016-04-30 23:00:00'\n",
    "\n",
    "startValidation = '2016-05-01 00:00:00'\n",
    "endValidation   = '2016-05-31 23:00:00'\n",
    "\n",
    "startTest = '2016-06-01 00:00:00'\n",
    "endTest   = '2016-06-30 23:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y1', 'y2', 'y3', 'y4', 'y5', 'y6', 'y']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetList = ['y1','y2','y3','y4','y5','y6']\n",
    "dropList = targetList\n",
    "dropList.append('y')\n",
    "dropList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainSet = df3.query('index >= @startTrain and index <= @endValidation') \n",
    "#validationSet = df3.query('intrainSetdex >= @startValidation and index <= @endValidation')\n",
    "testSet = df3.query('index >= @startTest and index <= @endTest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953947542866\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/j/rsl+Uhu9r+QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fae457d7ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "treeReg = DTR(random_state=42)\n",
    "treeReg.fit(trainSet.drop(dropList,axis = 1),trainSet.y)\n",
    "regression1 = treeReg.predict(df3.drop(dropList,axis = 1))\n",
    "#df3 = df3.assign(regressor1 = regression1)\n",
    "plt.plot(regression1)\n",
    "print treeReg.score(testSet.drop(dropList,axis = 1),testSet.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f3355bf3ce32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregression1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtreeReg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropList\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    367\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    380\u001b[0m                                       force_all_finite)\n\u001b[1;32m    381\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.values_from_object (pandas/_libs/lib.c:4618)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3174\u001b[0m         \u001b[0;34m\"\"\"same as values (but handles sparseness conversions)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dtype_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mas_matrix\u001b[0;34m(self, columns)\u001b[0m\n\u001b[1;32m   3140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mas_matrix\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m   3448\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3450\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3475\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3476\u001b[0m             \u001b[0mrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3477\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3478\u001b[0m             \u001b[0mitemmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \"\"\"\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "regression1 = treeReg.predict(df3.drop(dropList,axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df3.assign(regressor1 = regression1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linReg = linear_model.Ridge()\n",
    "linReg.fit(trainSet.drop(dropList,axis = 1),trainSet.y)\n",
    "regression2 = linReg.predict(testSet.drop(dropList,axis = 1))\n",
    "#df3 = df3.assign(regressor1 = regression1)\n",
    "plt.plot(regression2)\n",
    "print linReg.score(testSet.drop(dropList,axis = 1),testSet.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print linReg.score(df3.loc[startTest:endTest,:].drop(dropList,axis = 1),df3.loc[startTest:endTest,'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regression1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df3 = df3.assign(regressor1 = regression1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь надо обучить SARIMAX модель для каждого ряда и получить предсказания.\n",
    "Для тестирования выбираем ряд 1075. Код SARIMAX модели берём из 4й недели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsGroups = df3.groupby('region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regId = '1075'\n",
    "ts = tsGroups.get_group(regId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# получаем параметры SARIMAX модели\n",
    "params = sarimaxParams.get(regId)\n",
    "params = (1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ps = range(1, 5)\n",
    "d  = 1\n",
    "qs = range(1, 5)\n",
    "\n",
    "Ps = range(1, 3)\n",
    "D  = 1\n",
    "Qs = range(1, 3)\n",
    "\n",
    "pList = list(product(ps, qs, Ps, Qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endog = ts.loc[startTrain:endValidation,'y']\n",
    "exog = ts.loc[startTrain:endValidation,'regressor1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "best_aic = float(\"inf\")\n",
    "\n",
    "for params in pList:\n",
    "    print params\n",
    "    try:\n",
    "        mSARIMA=sm.tsa.statespace.SARIMAX(ts.loc[startTrain:endValidation,'y'], order=[params[0], 2, params[1]],\n",
    "                                  seasonal_order=(params[2], 1, params[3], 24),\n",
    "                                  exog = ts.loc[startTrain:endValidation,'regressor1']).fit(disp=1)\n",
    "    except Exception as inst:\n",
    "        print inst           # __str__ allows args to be printed directly\n",
    "        continue \n",
    "    else:     \n",
    "        aic = mSARIMA.aic\n",
    "        print('AIC',aic) \n",
    "        #сохраняем лучшую модель, aic, параметры\n",
    "        if aic < best_aic:\n",
    "            best_model = mSARIMA\n",
    "            best_aic = aic\n",
    "            best_param = param\n",
    "        results.append([param, mSARIMA.aic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "endog = ts.loc[:,'y']\n",
    "exog = ts.loc[:,'regressor1']\n",
    "\n",
    "plt.figure(figsize=[20,10])\n",
    "endog.plot()\n",
    "exog.plot()\n",
    "plt.xlim(['05-2016','07-2016'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(endog-exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[np.isnan(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[~np.isfinite(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Learn SARIMAX'\n",
    "try:\n",
    "    mSARIMA=sm.tsa.statespace.SARIMAX(ts, order=[params[0], 2, params[1]],\n",
    "                                      seasonal_order=(params[2], 1, params[3], 24),\n",
    "                                      exog = r_pr, enforce_invertibility = True).fit(disp=1);\n",
    "except Exception as inst:\n",
    "    print type(inst)     \n",
    "    print inst          \n",
    "\n",
    "# получаем предсказания регрессора на весь диапазон дат (обучение+предсказание)\n",
    "exog = getRegressor(regressor,startFit,endPrediction)\n",
    "# получаем данные о поездкахы на весь диапазон дат\n",
    "endog = df.loc[startFit:endPrediction,tsId]\n",
    "\n",
    "# создаём новую модель, которую будет использовать для предсказания\n",
    "# Для чего такой финт ушами - не понимаю до сих пор\n",
    "try:\n",
    "    model_fitted = sm.tsa.statespace.SARIMAX(endog, order=[params[0], 1, params[1]],\n",
    "                                         seasonal_order=(params[2], 1, params[3], 24),\n",
    "                                         exog = exog).filter(mSARIMA.params)\n",
    "except Exception as inst:\n",
    "    print 'Can not create the model'\n",
    "    print inst\n",
    "    continue\n",
    "\n",
    "# проходим по всему диапазону дат предсказаний\n",
    "print 'Make prediction'\n",
    "for firstLag in predictionRange[:-5]:\n",
    "    lastLag = firstLag+datetime.timedelta(hours = 5)\n",
    "    # prediction\n",
    "    try:\n",
    "        predicted_data = model_fitted.predict(firstLag, lastLag, dynamic=True, exog = exog[firstLag:lastLag])\n",
    "    except Exception as inst:\n",
    "        print 'Prediction error'\n",
    "        print inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так мы получили регрессионные предсказания для всех регионов на весь доступный диапазон дат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите вашу любимую регрессионную модель и настройте её на каждом из шести наборов данных, подбирая гиперпараметры на мае 2016. Желательно, чтобы модель:\n",
    "<ul>\n",
    "<li>Допускала попарные взаимодействия между признаками\n",
    "<li>Была устойчивой к избыточному количеству признаков (например, использовала регуляризаторы)\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем обучить Ridge классификатор с L2 регуляризацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "paramsAlpha = np.linspace(0.1,1,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestModels = dict()\n",
    "for target in targetList:\n",
    "    print target\n",
    "    dropCols = [x for x in targetList if x != target ]\n",
    "    dropCols.append('y')\n",
    "    dropCols.append('index')\n",
    "    tmpTrain = trainSet.drop(dropCols,axis = 1)\n",
    "    tmpTrain.rename(columns={target:'y'},inplace=True)\n",
    "    \n",
    "    tmpValidation = validationSet.drop(dropCols,axis = 1)\n",
    "    tmpValidation.rename(columns={target:'y'},inplace=True)\n",
    "    \n",
    "    minErr = np.inf\n",
    "    bestAlpha = 0\n",
    "    \n",
    "    \n",
    "    for a in paramsAlpha:\n",
    "        regressor = linear_model.Ridge(alpha= a)\n",
    "        regressor.fit(tmpTrain.drop('y',axis = 1),tmpTrain.loc[:,'y'])\n",
    "        prediction = regressor.predict(tmpValidation.drop('y',axis = 1))\n",
    "        err = np.abs(prediction - tmpValidation.loc[:,'y'])\n",
    "        err = err.mean()\n",
    "        print a, err\n",
    "        if err <minErr:\n",
    "            minErr = err\n",
    "            bestAlpha = a\n",
    "            bestModel = regressor\n",
    "    \n",
    "    bestModels.update({target:bestModel})\n",
    "            \n",
    "    print 'Smallest error {:2.3f} at a = {:2.3f}'.format(err,a)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now there are three regressors. WE have to use them.\n",
    "#np.save('bestModels.npy',bestModels)\n",
    "#bestModels = np.load('bestModels.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bestModels = dict()\n",
    "\n",
    "\n",
    "for target in targetList:\n",
    "    print target\n",
    "    dropCols = [x for x in targetList if x != target ]\n",
    "    dropCols.append('y')\n",
    "    dropCols.append('index')\n",
    "    tmpTrain = trainSet.drop(dropCols,axis = 1)\n",
    "    tmpTrain.rename(columns={target:'y'},inplace=True)\n",
    "    \n",
    "    tmpValidation = validationSet.drop(dropCols,axis = 1)\n",
    "    tmpValidation.rename(columns={target:'y'},inplace=True)\n",
    "    \n",
    "    regressor = DTR()\n",
    "    regressor.fit(tmpTrain.drop('y',axis = 1),tmpTrain.loc[:,'y'])\n",
    "    prediction = regressor.predict(tmpValidation.drop('y',axis = 1))\n",
    "    err = np.abs(prediction - tmpValidation.loc[:,'y'])\n",
    "    err = err.mean()\n",
    "\n",
    "    bestModels.update({target:regressor})\n",
    "            \n",
    "    print 'Smallest error {:2.3f} at a = {:2.3f}'.format(err,a)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dropCols = ['index','y','y1','y2','y3','y4','y5','y6']\n",
    "prediction = getTrips(testSet.drop(dropCols, axis = 1))\n",
    "\n",
    "predictionDf = pd.DataFrame(prediction.T,columns=['y1','y2','y3','y4','y5','y6'])\n",
    "predictionDf.set_index(testSet.index,inplace=True)\n",
    "predictionDf = predictionDf.merge(regDf,left_index=True,right_index=True,how='left')\n",
    "predictionDf = predictionDf.round()\n",
    "\n",
    "diff  = np.abs(predictionDf.y1-testSet.y1)+np.abs(predictionDf.y2-testSet.y2)+np.abs(predictionDf.y3-testSet.y3)+np.abs(predictionDf.y4-testSet.y4)+np.abs(predictionDf.y5-testSet.y5)+np.abs(predictionDf.y6-testSet.y6)\n",
    "print 'Error is', diff.mean()/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# теперь надо сохранить это в файл\n",
    "fName = 'res_week5-4.csv'\n",
    "saveResults(predictionDf,fName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictionDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testSet.query(\"region == '2168'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "deal with the dictionary of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('sarimaxParams', sarimaxParams)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sarimaxParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
