{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frodos/anaconda/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from sklearn import preprocessing, linear_model\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.preprocessing import PolynomialFeatures, Normalizer, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "#import holidays\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Класс моделей ARIMA недостаточно богат для наших данных: с их помощью, например, никак нельзя учесть взаимосвязи между рядами. Это можно сделать с помощью векторной авторегрессии VARIMA, но её питоновская реализация не позволяет использовать регрессионные признаки. Кроме того, авторегрессионный подход не позволяет учитывать, например, взаимодействия между сезонными компонентами. Вы могли заметить, что форма суточных сезонных профилей в будни и выходные немного разная; явно моделировать этот эффект с помощью ARIMA не получится.\n",
    "\n",
    "Нам нужна более сложная модель. Давайте займёмся сведением задачи массового прогнозирования рядов к регрессионной постановке! Вам понадобится много признаков. Некоторые из них у вас уже есть — это:\n",
    "<ol>\n",
    "<li>идентификатор географической зоны\n",
    "<li>дата и время\n",
    "<li>количество поездок в периоды, предшествующие прогнозируемому\n",
    "<li>синусы, косинусы и тренды, которые вы использовали внутри регрессионной компоненты ARIMA\n",
    "<li>Кроме того, не спешите выбрасывать построенный вами на прошлой неделе прогнозы — из них может получиться хороший признак для регрессии!\n",
    "</ol>\n",
    "\n",
    "\n",
    "\n",
    "Вы можете попробовать разные регрессионный модели, но хорошие результаты, скорее всего, дадут такие, которые будут позволять признакам взаимодействовать друг с другом.\n",
    "\n",
    "Поскольку прогноз нужен на 6 часов вперёд, проще всего будет построить 6 независимых регрессионных моделей — одна для прогнозирования y^T+1|T, другая для y^T+2|T и т.д.\n",
    "\n",
    "<ol>Чтобы сдать задание, выполните следующую последовательность действий.\n",
    "<li>Для каждой из шести задач прогнозирования y^T+i|T,i=1,…,6 сформируйте выборки. Откликом будет yT+i при всевозможных значениях T, а признаки можно использовать следующие:\n",
    "<ul>\n",
    "<li>идентификатор географической зоны — категориальный\n",
    "<li>год, месяц, день месяца, день недели, час — эти признаки можно пробовать брать и категориальными, и непрерывными, можно даже и так, и так (done)\n",
    "<li>синусы, косинусы и тренды, которые вы использовали внутри регрессионной компоненты ARIMA (done)\n",
    "<li>сами значения прогнозов ARIMA y^T+i|TARIMA\n",
    "<li>количество поездок из рассматриваемого района в моменты времени yT,yT−1,…,yT−K (параметр K можно подбирать; попробуйте начать, например, с 6)\n",
    "<li>количество поездок из рассматриваемого района в моменты времени yT−24,yT−48,…,yT−24∗Kd (параметр Kd можно подбирать; попробуйте начать, например, с 2)\n",
    "<li>суммарное количество поездок из рассматриваемого района за предшествующие полдня, сутки, неделю, месяц\n",
    "</ul>\n",
    "Будьте внимательны при создании признаков — все факторы должны быть рассчитаны без использования информации из будущего: при прогнозировании y^T+i|T,i=1,…,6 вы можете учитывать только значения y до момента времени T включительно.\n",
    "\n",
    "<li>Разбейте каждую из шести выборок на три части:\n",
    "\n",
    "    обучающая, на которой будут настраиваться параметры моделей — всё до апреля 2016\n",
    "    тестовая, на которой вы будете подбирать значения гиперпараметров — май 2016\n",
    "    итоговая, которая не будет использоваться при настройке моделей вообще — июнь 2016\n",
    "\n",
    "<li>Выберите вашу любимую регрессионную модель и настройте её на каждом из шести наборов данных, подбирая гиперпараметры на мае 2016. Желательно, чтобы модель:\n",
    "\n",
    "    допускала попарные взаимодействия между признаками\n",
    "    была устойчивой к избыточному количеству признаков (например, использовала регуляризаторы)\n",
    "\n",
    "<li>Выбранными моделями постройте для каждой географической зоны и каждого конца истории от 2016.04.30 23:00 до 2016.05.31 17:00 прогнозы на 6 часов вперёд; посчитайте в ноутбуке ошибку прогноза по следующему функционалу:\n",
    "Qmay=1R∗739∗6∑r=1R∑T=2016.04.3023:002016.05.3117:00∑i=16y^T|T+ir−yT+ir.\n",
    "Убедитесь, что ошибка полученных прогнозов, рассчитанная согласно функционалу Q, определённому на прошлой неделе, уменьшилась по сравнению с той, которую вы получили методом индивидуального применения моделей ARIMA. Если этого не произошло, попробуйте улучшить ваши модели.\n",
    "\n",
    "<li>Итоговыми моделями постройте прогнозы для каждого конца истории от 2016.05.31 23:00 до 2016.06.30 17:00 и запишите все результаты в один файл в формате geoID, histEndDay, histEndHour, step, y. Здесь geoID — идентификатор зоны, histEndDay — день конца истории в формате id,y, где столбец id состоит из склеенных через подчёркивание идентификатора географической зоны, даты конца истории, часа конца истории и номера отсчёта, на который делается предсказание (1-6); столбец y — ваш прогноз.\n",
    "\n",
    "<li>Загрузите полученный файл на kaggle: https://inclass.kaggle.com/c/yellowtaxi. Добавьте в ноутбук ссылку на сабмишн.\n",
    "\n",
    "<li>Загрузите ноутбук в форму."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# id нужных регионов\n",
    "regsDf = pd.read_csv('../crowdRegs.csv',names=['id','regId']);  \n",
    "\n",
    "# временные ряды для этих регионов\n",
    "df = pd.read_pickle('../loadData/crowdRegs3.pcl')\n",
    "df.columns = regsDf.regId.values.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# эта функция возвращает фичи, общие для всех колонок (временные гармоники, даты)\n",
    "def getCommonFeature(Kw=5,Ka=2,addHolidays = True):\n",
    "    #parameters:\n",
    "    #  Kw is number of weeks harmonics\n",
    "    #  Ka is number of annual harmonics\n",
    "    # holidays - add bool feature for holidays\n",
    "    \n",
    "    \n",
    "    df2 = pd.DataFrame(index=index1)\n",
    "    df2 = df2.assign(linear = (df2.index - datetime.datetime(2014,1,1,0,0,0))/np.timedelta64(1, 'h'))\n",
    "    \n",
    "    if addHolidays:  \n",
    "        us_holidays = holidays.UnitedStates(state=\"NY\")\n",
    "        # категориальная переменная для выходных дней\n",
    "        df2 = df2.assign(holidays = df2.index.date)\n",
    "        df2.holidays =  df2.loc[:,'holidays'].apply(lambda x: 1 if x in us_holidays else 0)\n",
    "\n",
    "    # час — эти признаки можно пробовать брать и категориальными\n",
    "    # и непрерывными, можно даже и так, и так\n",
    "\n",
    "    # добавляем гармонические фичи\n",
    "    for ind in range(1,Kw+1):\n",
    "        df2['weekCos'+str(ind)]= np.cos(np.pi*df2.linear*ind/168);\n",
    "        df2['weekSin'+str(ind)]= np.sin(np.pi*df2.linear*ind/168);\n",
    "    \n",
    "    for ind in range(1,Ka+1):\n",
    "        df2['yearCos'+str(ind)]= np.cos(2*np.pi*df2.linear*ind/8766);\n",
    "        df2['yearSin'+str(ind)]= np.sin(2*np.pi*df2.linear*ind/8766);\n",
    "\n",
    "    # добавляем числовое и категориальные свойства для дней недели\n",
    "    df2 = df2.assign(dayOfWeek = df2.index.dayofweek)\n",
    "    lbDays = preprocessing.LabelBinarizer()\n",
    "    lbDays.fit(list(np.arange(6)))\n",
    "    DoW = pd.DataFrame(lbDays.transform(df2.index.dayofweek),columns = ['dayOfWeek_'+str(x) for x in np.arange(6)],\n",
    "               index = df2.index)      \n",
    "    df2 = df2.merge(DoW,left_index=True,right_index=True)\n",
    "\n",
    "    # добавляем dummy variables для месяца\n",
    "    df2 = df2.assign(month = df2.index.month)\n",
    "    lbMonths = preprocessing.LabelBinarizer()\n",
    "    lbMonths.fit(list(np.arange(12)))\n",
    "    Months = pd.DataFrame(lbMonths.transform(df2.index.month),columns = ['month_'+str(x) for x in np.arange(1,13)],\n",
    "                  index = df2.index)      \n",
    "    df2 = df2.merge(Months,left_index=True,right_index=True);\n",
    "\n",
    "    # добавляем год (вещественный)\n",
    "    df2 = df2.assign(year = df.index.year)\n",
    "\n",
    "    # добавляем день месяца (вещественный)\n",
    "    df2 = df2.assign(day = df.index.day)\n",
    "\n",
    "    # добавляем час (вещественный и категориальный)\n",
    "    df2 = df2.assign(hour = df.index.hour)\n",
    "    lbHours = preprocessing.LabelBinarizer()\n",
    "    lbHours.fit(list(np.arange(24)))\n",
    "    Hours = pd.DataFrame(lbHours.transform(df2.index.hour),columns = ['hour_'+str(x) for x in np.arange(24)],\n",
    "               index = df2.index)      \n",
    "    df2 = df2.merge(Hours,left_index=True,right_index=True)\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# эта функция сохраняет данные в файл\n",
    "def saveResults(rdf, fName, delta = 30):\n",
    "    rnd = np.round\n",
    "\n",
    "    f = open(fName,'w')\n",
    "    f.writelines('id,y\\n')\n",
    "\n",
    "    for ind, row in rdf.reset_index().iterrows():\n",
    "        historyStart = row.date\n",
    "\n",
    "        if historyStart > datetime.datetime(2016,6,30,17):\n",
    "            continue\n",
    "\n",
    "        s0 = str(row.region)+'_'+ str(datetime.datetime.strftime(historyStart, \"%Y-%m-%d\"))+ '_'+ str(historyStart.hour)\n",
    "\n",
    "        s1 = s0 +'_1,'+str(rnd(row.get('y1_pr'))+delta) + '\\n'\n",
    "        f.writelines(s1)\n",
    "\n",
    "        s2 = s0 +'_2,'+str(rnd(row.get('y2_pr'))+delta) + '\\n'\n",
    "        f.writelines(s2)\n",
    "\n",
    "        s3 = s0 +'_3,'+str(rnd(row.get('y3_pr'))+delta) + '\\n'\n",
    "        f.writelines(s3)\n",
    "\n",
    "        s4 = s0 +'_4,'+str(rnd(row.get('y4_pr'))+delta) + '\\n'\n",
    "        f.writelines(s4)\n",
    "\n",
    "        s5 = s0 +'_5,'+str(rnd(row.get('y5_pr'))+delta) + '\\n'\n",
    "        f.writelines(s5)\n",
    "\n",
    "        s6 = s0 +'_6,'+str(rnd(row.get('y6_pr'))+delta) + '\\n'\n",
    "        f.writelines(s6)\n",
    "\n",
    "    f.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processSeries(df,Kh = 6, Kp = 2):\n",
    "    \"\"\"\n",
    "    Обработка одного данного ряда \n",
    "    parameters:\n",
    "        df - начальный датафрейм, из которого выберем для обработки один ряд\n",
    "        tReg - название ряда, который надо обработать\n",
    "        Kh - количество отслеживаемых прошлых суточных лагов \"назад\"\n",
    "        Kp - количество отслеживаемых прошлых периодических лагов (период 24 часа)\n",
    "\n",
    "    \"\"\"\n",
    " \n",
    "\n",
    "    tDf = df.copy()\n",
    "    for timeLag in np.arange(1,Kh+1):\n",
    "        name = 'hourLag_'+str(timeLag)\n",
    "        tDf.loc[:,name] = tDf.y.shift(periods=timeLag)\n",
    "\n",
    "        \n",
    "\n",
    "    for timeLag in np.arange(1,Kp+1):\n",
    "        name = 'periodicLag_'+str(timeLag)\n",
    "        tDf.loc[:,name] = tDf.y.shift(periods=timeLag*24)\n",
    "\n",
    "\n",
    "    tDf.fillna(0,inplace=True)    \n",
    "\n",
    "    # суммарное количество поездок из рассматриваемого района за предшествующие полдня, сутки, неделю, месяц\n",
    "    tDf.loc[:,'mean12'] = tDf.y.rolling(window = 12, min_periods = 1).mean()\n",
    "    tDf.loc[:,'mean24'] = tDf.y.rolling(window = 24, min_periods = 1).mean()\n",
    "    tDf.loc[:,'meanWeek'] = tDf.y.rolling(window = 168, min_periods = 1).mean()\n",
    "    tDf.loc[:,'meanMonth'] = tDf.y.rolling(window = 720, min_periods = 1).mean()\n",
    "\n",
    "    \n",
    "     \n",
    "    tDf.loc[:,'max12'] = tDf.y.rolling(window = 12, min_periods = 1).max()\n",
    "    tDf.loc[:,'max24'] = tDf.y.rolling(window = 24, min_periods = 1).max()\n",
    "    tDf.loc[:,'maxWeek'] = tDf.y.rolling(window = 168, min_periods = 1).max()\n",
    "    tDf.loc[:,'maxMonth'] = tDf.y.rolling(window = 720, min_periods = 1).max()\n",
    "\n",
    "    \n",
    "    \n",
    "    tDf.loc[:,'min12'] = tDf.y.rolling(window = 12, min_periods = 1).min()\n",
    "    tDf.loc[:,'min24'] = tDf.y.rolling(window = 24, min_periods = 1).min()\n",
    "    tDf.loc[:,'minWeek'] = tDf.y.rolling(window = 168, min_periods = 1).min()\n",
    "    tDf.loc[:,'minMonth'] = tDf.y.rolling(window = 720, min_periods = 1).min()\n",
    "\n",
    "        \n",
    "    return tDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# вычисление ошибки\n",
    "def calcMAE(inpDf):\n",
    "    score = 0\n",
    "    testDf = inpDf.reset_index()\n",
    "    for k, v in saveDict.iteritems():\n",
    "        score += MAE(testDf.loc[:,k],testDf.loc[:,v])\n",
    "    score = score / 6.0    \n",
    "    print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create multyindex dataframe\n",
    "index1 = df.index # time is first index\n",
    "index2 = df.columns.values.astype(int)\n",
    "\n",
    "mIndex = pd.MultiIndex.from_product([index2, index1],names=['region','date'])\n",
    "df_test = pd.DataFrame(columns=['y'],index = mIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1075</th>\n",
       "      <th>2014-01-01 00:00:00</th>\n",
       "      <td>87</td>\n",
       "      <td>92.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 01:00:00</th>\n",
       "      <td>92</td>\n",
       "      <td>108.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 02:00:00</th>\n",
       "      <td>108</td>\n",
       "      <td>77.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 03:00:00</th>\n",
       "      <td>77</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 04:00:00</th>\n",
       "      <td>47</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              y     y1     y2    y3    y4    y5    y6\n",
       "region date                                                          \n",
       "1075   2014-01-01 00:00:00   87   92.0  108.0  77.0  47.0  22.0  10.0\n",
       "       2014-01-01 01:00:00   92  108.0   77.0  47.0  22.0  10.0  18.0\n",
       "       2014-01-01 02:00:00  108   77.0   47.0  22.0  10.0  18.0  19.0\n",
       "       2014-01-01 03:00:00   77   47.0   22.0  10.0  18.0  19.0  28.0\n",
       "       2014-01-01 04:00:00   47   22.0   10.0  18.0  19.0  28.0  37.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create MultiIndex dataframe with target variables    \n",
    "for k in index2:\n",
    "    pos = idx[k,:]\n",
    "    df_test.loc[idx[k,:],'y'] = df.loc[:,str(k)].values\n",
    "    # create target variables\n",
    "    df_test.loc[pos,'y1'] = df_test.loc[pos,'y'].shift(-1).fillna(0)\n",
    "    df_test.loc[pos,'y2'] = df_test.loc[pos,'y'].shift(-2).fillna(0)\n",
    "    df_test.loc[pos,'y3'] = df_test.loc[pos,'y'].shift(-3).fillna(0)\n",
    "    df_test.loc[pos,'y4'] = df_test.loc[pos,'y'].shift(-4).fillna(0)\n",
    "    df_test.loc[pos,'y5'] = df_test.loc[pos,'y'].shift(-5).fillna(0)\n",
    "    df_test.loc[pos,'y6'] = df_test.loc[pos,'y'].shift(-6).fillna(0)\n",
    "    \n",
    "df_test.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linear</th>\n",
       "      <th>weekCos1</th>\n",
       "      <th>weekSin1</th>\n",
       "      <th>weekCos2</th>\n",
       "      <th>weekSin2</th>\n",
       "      <th>weekCos3</th>\n",
       "      <th>weekSin3</th>\n",
       "      <th>weekCos4</th>\n",
       "      <th>weekSin4</th>\n",
       "      <th>weekCos5</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 01:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.018699</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.998427</td>\n",
       "      <td>0.056070</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>0.074730</td>\n",
       "      <td>0.995632</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 02:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>0.074730</td>\n",
       "      <td>0.993712</td>\n",
       "      <td>0.111964</td>\n",
       "      <td>0.988831</td>\n",
       "      <td>0.149042</td>\n",
       "      <td>0.982566</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 03:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.998427</td>\n",
       "      <td>0.056070</td>\n",
       "      <td>0.993712</td>\n",
       "      <td>0.111964</td>\n",
       "      <td>0.985871</td>\n",
       "      <td>0.167506</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>0.222521</td>\n",
       "      <td>0.960917</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 04:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>0.074730</td>\n",
       "      <td>0.988831</td>\n",
       "      <td>0.149042</td>\n",
       "      <td>0.974928</td>\n",
       "      <td>0.222521</td>\n",
       "      <td>0.955573</td>\n",
       "      <td>0.294755</td>\n",
       "      <td>0.930874</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     linear  weekCos1  weekSin1  weekCos2  weekSin2  weekCos3  \\\n",
       "date                                                                            \n",
       "2014-01-01 00:00:00     0.0  1.000000  0.000000  1.000000  0.000000  1.000000   \n",
       "2014-01-01 01:00:00     1.0  0.999825  0.018699  0.999301  0.037391  0.998427   \n",
       "2014-01-01 02:00:00     2.0  0.999301  0.037391  0.997204  0.074730  0.993712   \n",
       "2014-01-01 03:00:00     3.0  0.998427  0.056070  0.993712  0.111964  0.985871   \n",
       "2014-01-01 04:00:00     4.0  0.997204  0.074730  0.988831  0.149042  0.974928   \n",
       "\n",
       "                     weekSin3  weekCos4  weekSin4  weekCos5   ...     hour_14  \\\n",
       "date                                                          ...               \n",
       "2014-01-01 00:00:00  0.000000  1.000000  0.000000  1.000000   ...           0   \n",
       "2014-01-01 01:00:00  0.056070  0.997204  0.074730  0.995632   ...           0   \n",
       "2014-01-01 02:00:00  0.111964  0.988831  0.149042  0.982566   ...           0   \n",
       "2014-01-01 03:00:00  0.167506  0.974928  0.222521  0.960917   ...           0   \n",
       "2014-01-01 04:00:00  0.222521  0.955573  0.294755  0.930874   ...           0   \n",
       "\n",
       "                     hour_15  hour_16  hour_17  hour_18  hour_19  hour_20  \\\n",
       "date                                                                        \n",
       "2014-01-01 00:00:00        0        0        0        0        0        0   \n",
       "2014-01-01 01:00:00        0        0        0        0        0        0   \n",
       "2014-01-01 02:00:00        0        0        0        0        0        0   \n",
       "2014-01-01 03:00:00        0        0        0        0        0        0   \n",
       "2014-01-01 04:00:00        0        0        0        0        0        0   \n",
       "\n",
       "                     hour_21  hour_22  hour_23  \n",
       "date                                            \n",
       "2014-01-01 00:00:00        0        0        0  \n",
       "2014-01-01 01:00:00        0        0        0  \n",
       "2014-01-01 02:00:00        0        0        0  \n",
       "2014-01-01 03:00:00        0        0        0  \n",
       "2014-01-01 04:00:00        0        0        0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create common features\n",
    "commonFeatures = getCommonFeature(addHolidays=False)\n",
    "commonFeatures.index.name = 'date'\n",
    "commonFeatures.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подгрузим и отобразим данные по погоде"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weatherDf = pd.read_pickle('../data/weatherDf.pcl')\n",
    "#weatherDf.index.name = 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weatherDf = weatherDf[~weatherDf.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[15,10])\n",
    "\n",
    "plt.subplot(311)\n",
    "weatherDf.temp_val.plot()\n",
    "plt.title('Temperature')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('C')\n",
    "plt.xticks([])\n",
    "\n",
    "plt.subplot(312)\n",
    "weatherDf.precip.plot()\n",
    "plt.title('Precipitation')\n",
    "plt.xlabel('')\n",
    "plt.xticks([])\n",
    "plt.ylabel('h')\n",
    "\n",
    "plt.subplot(313)\n",
    "weatherDf.snow.plot()\n",
    "plt.title('Snow')\n",
    "plt.ylabel('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commonFeatures = commonFeatures.merge(weatherDf,left_index=True,right_index=True,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join common features and add unique ones for each subgroup \n",
    "final = pd.DataFrame()\n",
    "for k in index2:\n",
    "    # create tatget variables\n",
    "    pos = idx[k,:]\n",
    "    tmp = processSeries(df_test.loc[pos,:].join(commonFeatures),Kh = 12, Kp = 4)\n",
    "    final = pd.concat([final,tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropList = ['y1','y2','y3','y4','y5','y6','date','region'] # колонки, которые не надо учитывать в регрессоре\n",
    "targetList= ['y1','y2','y3','y4','y5','y6']                # целевые переменные для регрессоров "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define time frames\n",
    "startTrain = '2016-01-01 00:00:00'\n",
    "endTrain   = '2016-04-30 23:00:00'\n",
    "\n",
    "startValidation = '2016-05-01 00:00:00'\n",
    "endValidation   = '2016-05-31 23:00:00'\n",
    "\n",
    "startTest = '2016-05-31 23:00:00'\n",
    "endTest   = '2016-06-30 23:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final.to_pickle('finalDf.pcl')\n",
    "final = pd.read_pickle('finalDf.pcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dataframe to save prediction\n",
    "resIndex = pd.MultiIndex.from_product([final.index.levels[0],pd.date_range(start=startTest,end=endTest,freq='1H')],\n",
    "                                    names=['region','date'])\n",
    "df_res = pd.DataFrame(columns=['y1','y1_pr','y2','y2_pr','y3','y3_pr','y4','y4_pr','y5','y5_pr','y6','y6_pr'],index = resIndex)\n",
    "df_res2 = pd.DataFrame(columns=['y1','y1_pr','y2','y2_pr','y3','y3_pr','y4','y4_pr','y5','y5_pr','y6','y6_pr'],index = resIndex)\n",
    "saveDict = {'y1':'y1_pr','y2':'y2_pr','y3':'y3_pr','y4':'y4_pr','y5':'y5_pr','y6':'y6_pr'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>linear</th>\n",
       "      <th>weekCos1</th>\n",
       "      <th>weekSin1</th>\n",
       "      <th>...</th>\n",
       "      <th>meanWeek</th>\n",
       "      <th>meanMonth</th>\n",
       "      <th>max12</th>\n",
       "      <th>max24</th>\n",
       "      <th>maxWeek</th>\n",
       "      <th>maxMonth</th>\n",
       "      <th>min12</th>\n",
       "      <th>min24</th>\n",
       "      <th>minWeek</th>\n",
       "      <th>minMonth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2168</th>\n",
       "      <th>2016-06-30 19:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21883.0</td>\n",
       "      <td>0.693761</td>\n",
       "      <td>0.720205</td>\n",
       "      <td>...</td>\n",
       "      <td>1.351190</td>\n",
       "      <td>30.966667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 20:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21884.0</td>\n",
       "      <td>0.680173</td>\n",
       "      <td>0.733052</td>\n",
       "      <td>...</td>\n",
       "      <td>1.351190</td>\n",
       "      <td>30.812500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 21:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21885.0</td>\n",
       "      <td>0.666347</td>\n",
       "      <td>0.745642</td>\n",
       "      <td>...</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>30.633333</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 22:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21886.0</td>\n",
       "      <td>0.652287</td>\n",
       "      <td>0.757972</td>\n",
       "      <td>...</td>\n",
       "      <td>1.351190</td>\n",
       "      <td>30.462500</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30 23:00:00</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21887.0</td>\n",
       "      <td>0.638000</td>\n",
       "      <td>0.770036</td>\n",
       "      <td>...</td>\n",
       "      <td>1.345238</td>\n",
       "      <td>30.279167</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            y   y1   y2   y3   y4   y5   y6   linear  \\\n",
       "region date                                                            \n",
       "2168   2016-06-30 19:00:00  1  0.0  1.0  0.0  0.0  0.0  0.0  21883.0   \n",
       "       2016-06-30 20:00:00  0  1.0  0.0  0.0  0.0  0.0  0.0  21884.0   \n",
       "       2016-06-30 21:00:00  1  0.0  0.0  0.0  0.0  0.0  0.0  21885.0   \n",
       "       2016-06-30 22:00:00  0  0.0  0.0  0.0  0.0  0.0  0.0  21886.0   \n",
       "       2016-06-30 23:00:00  0  0.0  0.0  0.0  0.0  0.0  0.0  21887.0   \n",
       "\n",
       "                            weekCos1  weekSin1    ...     meanWeek  meanMonth  \\\n",
       "region date                                       ...                           \n",
       "2168   2016-06-30 19:00:00  0.693761  0.720205    ...     1.351190  30.966667   \n",
       "       2016-06-30 20:00:00  0.680173  0.733052    ...     1.351190  30.812500   \n",
       "       2016-06-30 21:00:00  0.666347  0.745642    ...     1.357143  30.633333   \n",
       "       2016-06-30 22:00:00  0.652287  0.757972    ...     1.351190  30.462500   \n",
       "       2016-06-30 23:00:00  0.638000  0.770036    ...     1.345238  30.279167   \n",
       "\n",
       "                            max12  max24  maxWeek  maxMonth  min12  min24  \\\n",
       "region date                                                                 \n",
       "2168   2016-06-30 19:00:00    2.0    5.0      9.0     194.0    0.0    0.0   \n",
       "       2016-06-30 20:00:00    2.0    5.0      9.0     194.0    0.0    0.0   \n",
       "       2016-06-30 21:00:00    2.0    5.0      9.0     194.0    0.0    0.0   \n",
       "       2016-06-30 22:00:00    2.0    5.0      9.0     194.0    0.0    0.0   \n",
       "       2016-06-30 23:00:00    2.0    5.0      9.0     194.0    0.0    0.0   \n",
       "\n",
       "                            minWeek  minMonth  \n",
       "region date                                    \n",
       "2168   2016-06-30 19:00:00      0.0       0.0  \n",
       "       2016-06-30 20:00:00      0.0       0.0  \n",
       "       2016-06-30 21:00:00      0.0       0.0  \n",
       "       2016-06-30 22:00:00      0.0       0.0  \n",
       "       2016-06-30 23:00:00      0.0       0.0  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# выберу первую группу и протестирую на ней регрессор и саримах\n",
    "dropList = ['y1','y2','y3','y4','y5','y6','date'] # колонки, которые не надо учитывать в регрессоре\n",
    "sarimaxCols = ['y1_sarimax','y2_sarimax','y3_sarimax','y4_sarimax','y5_sarimax','y6_sarimax']\n",
    "\n",
    "from itertools import product\n",
    "ps = range(3, 0, -1)\n",
    "d  = 1\n",
    "qs = range(3, 0, -1)\n",
    "Ps = range(2, 0, -1)\n",
    "D  = 1\n",
    "Qs = range(2, 0, -1)\n",
    "pList = list(product(ps, qs, Ps, Qs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "      <th>y5</th>\n",
       "      <th>y6</th>\n",
       "      <th>linear</th>\n",
       "      <th>weekCos1</th>\n",
       "      <th>weekSin1</th>\n",
       "      <th>...</th>\n",
       "      <th>min12</th>\n",
       "      <th>min24</th>\n",
       "      <th>minWeek</th>\n",
       "      <th>minMonth</th>\n",
       "      <th>y1_sarimax</th>\n",
       "      <th>y2_sarimax</th>\n",
       "      <th>y3_sarimax</th>\n",
       "      <th>y4_sarimax</th>\n",
       "      <th>y5_sarimax</th>\n",
       "      <th>y6_sarimax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1075</th>\n",
       "      <th>2014-01-01 00:00:00</th>\n",
       "      <td>87</td>\n",
       "      <td>92.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 01:00:00</th>\n",
       "      <td>92</td>\n",
       "      <td>108.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.018699</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 02:00:00</th>\n",
       "      <td>108</td>\n",
       "      <td>77.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 03:00:00</th>\n",
       "      <td>77</td>\n",
       "      <td>47.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.998427</td>\n",
       "      <td>0.056070</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 04:00:00</th>\n",
       "      <td>47</td>\n",
       "      <td>22.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.997204</td>\n",
       "      <td>0.074730</td>\n",
       "      <td>...</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              y     y1     y2    y3    y4    y5    y6  linear  \\\n",
       "region date                                                                     \n",
       "1075   2014-01-01 00:00:00   87   92.0  108.0  77.0  47.0  22.0  10.0     0.0   \n",
       "       2014-01-01 01:00:00   92  108.0   77.0  47.0  22.0  10.0  18.0     1.0   \n",
       "       2014-01-01 02:00:00  108   77.0   47.0  22.0  10.0  18.0  19.0     2.0   \n",
       "       2014-01-01 03:00:00   77   47.0   22.0  10.0  18.0  19.0  28.0     3.0   \n",
       "       2014-01-01 04:00:00   47   22.0   10.0  18.0  19.0  28.0  37.0     4.0   \n",
       "\n",
       "                            weekCos1  weekSin1     ...      min12  min24  \\\n",
       "region date                                        ...                     \n",
       "1075   2014-01-01 00:00:00  1.000000  0.000000     ...       87.0   87.0   \n",
       "       2014-01-01 01:00:00  0.999825  0.018699     ...       87.0   87.0   \n",
       "       2014-01-01 02:00:00  0.999301  0.037391     ...       87.0   87.0   \n",
       "       2014-01-01 03:00:00  0.998427  0.056070     ...       77.0   77.0   \n",
       "       2014-01-01 04:00:00  0.997204  0.074730     ...       47.0   47.0   \n",
       "\n",
       "                            minWeek  minMonth  y1_sarimax  y2_sarimax  \\\n",
       "region date                                                             \n",
       "1075   2014-01-01 00:00:00     87.0      87.0           0           0   \n",
       "       2014-01-01 01:00:00     87.0      87.0           0           0   \n",
       "       2014-01-01 02:00:00     87.0      87.0           0           0   \n",
       "       2014-01-01 03:00:00     77.0      77.0           0           0   \n",
       "       2014-01-01 04:00:00     47.0      47.0           0           0   \n",
       "\n",
       "                            y3_sarimax  y4_sarimax  y5_sarimax  y6_sarimax  \n",
       "region date                                                                 \n",
       "1075   2014-01-01 00:00:00           0           0           0           0  \n",
       "       2014-01-01 01:00:00           0           0           0           0  \n",
       "       2014-01-01 02:00:00           0           0           0           0  \n",
       "       2014-01-01 03:00:00           0           0           0           0  \n",
       "       2014-01-01 04:00:00           0           0           0           0  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = final.assign(y1_sarimax = 0).assign(y2_sarimax = 0).assign(y3_sarimax = 0).assign(y4_sarimax = 0).assign(y5_sarimax = 0).assign(y6_sarimax = 0)\n",
    "final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 2, 2)\n",
      "Learn SARIMAX\n",
      "<type 'exceptions.ValueError'>\n",
      "Non-stationary starting autoregressive parameters found with `enforce_stationarity` set to True.\n",
      "(3, 3, 2, 1)\n",
      "Learn SARIMAX\n",
      "<type 'exceptions.ValueError'>\n",
      "Non-stationary starting autoregressive parameters found with `enforce_stationarity` set to True.\n",
      "(3, 3, 1, 2)\n",
      "Learn SARIMAX\n",
      "<type 'exceptions.ValueError'>\n",
      "Non-stationary starting autoregressive parameters found with `enforce_stationarity` set to True.\n",
      "(3, 3, 1, 1)\n",
      "Learn SARIMAX\n",
      "<type 'exceptions.ValueError'>\n",
      "Non-stationary starting autoregressive parameters found with `enforce_stationarity` set to True.\n",
      "(3, 2, 2, 2)\n",
      "Learn SARIMAX\n",
      "<type 'exceptions.ValueError'>\n",
      "Non-stationary starting autoregressive parameters found with `enforce_stationarity` set to True.\n",
      "(3, 2, 2, 1)\n",
      "Learn SARIMAX\n",
      "<type 'exceptions.ValueError'>\n",
      "Non-stationary starting autoregressive parameters found with `enforce_stationarity` set to True.\n",
      "(3, 2, 1, 2)\n",
      "Learn SARIMAX\n",
      "<type 'exceptions.ValueError'>\n",
      "Non-stationary starting autoregressive parameters found with `enforce_stationarity` set to True.\n",
      "(3, 2, 1, 1)\n",
      "Learn SARIMAX\n",
      "<type 'exceptions.ValueError'>\n",
      "Non-stationary starting autoregressive parameters found with `enforce_stationarity` set to True.\n",
      "(3, 1, 2, 2)\n",
      "Learn SARIMAX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frodos/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is ready\n"
     ]
    }
   ],
   "source": [
    "for regId in final.index.levels[0].values:\n",
    "    setDf = final.loc[idx[regId,startTrain:endTest],:]\n",
    "    setDf.reset_index(inplace=True,level=0)\n",
    "\n",
    "    train = setDf.loc[startTrain:endValidation,:].reset_index()\n",
    "    test  = setDf.loc[startTest:endTest,:].reset_index()\n",
    "\n",
    "    # first linear regressor\n",
    "    linReg = linear_model.Ridge()\n",
    "    linReg.fit(train.drop(dropList,axis=1),train.loc[:,'y1'])\n",
    "\n",
    "    # write to df\n",
    "    ts = pd.Series(linReg.predict(setDf.loc[startTrain:endTest,:].reset_index().drop(dropList,axis=1)),\n",
    "                   index=setDf.loc[startTrain:endTest,:].index)\n",
    "    setDf = setDf.merge(ts.shift(1).fillna(0).to_frame(name='regressor'),left_index=True,right_index=True)\n",
    "\n",
    "    # подбираем параметры\n",
    "    print 'Learn SARIMAX'\n",
    "    for params in pList:\n",
    "        print params\n",
    "\n",
    "        # обучаем SARIMAX модель\n",
    "        try:\n",
    "            mSARIMA=sm.tsa.statespace.SARIMAX(setDf.loc[startTrain:endValidation,'y'], order=[params[0], d, params[1]],\n",
    "                                              seasonal_order=(params[2], D, params[3], 24),\n",
    "                                              exog = setDf.loc[startTrain:endValidation,'regressor'], enforce_invertibility = True).fit(disp=1);\n",
    "        except Exception as inst:\n",
    "            print inst\n",
    "        else:\n",
    "            print 'Model is ready'\n",
    "            break\n",
    "\n",
    "    # создаём новую модель, которую будет использовать для предсказания\n",
    "    # Для чего такой финт ушами - не понимаю до сих пор\n",
    "    try:\n",
    "        model_fitted = sm.tsa.statespace.SARIMAX(setDf.loc[startTrain:endTest,'y'],\n",
    "                                                 order=[params[0], d, params[1]],\n",
    "                                                 seasonal_order=(params[2], D, params[3], 24),\n",
    "                                                 exog = setDf.loc[startTrain:endTest,'regressor'],\n",
    "                                                 enforce_invertibility = True).filter(mSARIMA.params)\n",
    "    except Exception as inst:\n",
    "        print 'Can not create the model'\n",
    "        print inst\n",
    "\n",
    "    # проходим по всему диапазону дат предсказаний\n",
    "    print 'Make prediction'\n",
    "    predictionRange = pd.date_range(startTrain,endTest, freq='H')\n",
    "    for historyStart in predictionRange[:-6]:\n",
    "        firstLag = historyStart+datetime.timedelta(hours = 1)\n",
    "        lastLag  = historyStart+datetime.timedelta(hours = 6)\n",
    "\n",
    "        # prediction\n",
    "        try:\n",
    "            predicted_data = model_fitted.predict(firstLag, lastLag, dynamic=True,\n",
    "                                                  exog = setDf.loc[firstLag:lastLag,'regressor'])\n",
    "        except Exception as inst:\n",
    "            print 'Prediction error'\n",
    "            print inst\n",
    "        else:\n",
    "            final.loc[idx[regId,historyStart],sarimaxCols] = predicted_data.values\n",
    "    final.to_pickle('final.pcl')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# собственно, сам регрессор\n",
    "for reg in final.index.levels[0].values:\n",
    "    train = final.loc[idx[reg,startTrain:endValidation],:].reset_index()\n",
    "    test  = final.loc[idx[reg,startTest:endTest],:].reset_index()\n",
    "    for target in targetList:\n",
    "        linReg.fit(train.drop(dropList,axis=1),train.loc[:,target])\n",
    "        prediction = linReg.predict(test.drop(dropList,axis=1))\n",
    "        prediction[prediction<0] = 0\n",
    "        df_res.loc[idx[reg,:], target] = test.loc[:,target].values\n",
    "        df_res.loc[idx[reg,:], saveDict.get(target)] = prediction\n",
    "    print reg #,' ', calcMAE(df_res)    \n",
    "df_res.head()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# собственно, сам регрессор\n",
    "for reg in final.index.levels[0].values:\n",
    "    train = final.loc[idx[reg,startTrain:endValidation],:].reset_index()\n",
    "    test  = final.loc[idx[reg,startTest:endTest],:].reset_index()\n",
    "    for target in targetList:\n",
    "        linReg.fit(train.drop(dropList,axis=1),train.loc[:,target])\n",
    "        prediction = linReg.predict(test.drop(dropList,axis=1))\n",
    "        prediction[prediction<0] = 0\n",
    "        df_res.loc[idx[reg,:], target] = test.loc[:,target].values\n",
    "        df_res.loc[idx[reg,:], saveDict.get(target)] = prediction\n",
    "    print reg #,' ', calcMAE(df_res)    \n",
    "df_res.head()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calcMAE(df_res)\n",
    "#saveResults(df_res,fName='02Aug.csv',delta=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На момент загрузки - 30е место в лидерборде со счётом 23.41763 (ник Frodos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавим нормализатор к регрессору."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linReg = linear_model.Ridge()\n",
    "\n",
    "ppl = Pipeline([('norm',MinMaxScaler()),('features',PolynomialFeatures(degree=2)),('regressor',linReg)])\n",
    "\n",
    "for reg in final.index.levels[0].values:\n",
    "    X_train = final.loc[idx[reg,startTrain:endValidation],:].reset_index().drop(dropList,axis=1)\n",
    "    X_test  = final.loc[idx[reg,startTest:endTest],:].reset_index().drop(dropList,axis=1)\n",
    "    \n",
    "    for target in targetList:\n",
    "        y_train = final.loc[idx[reg,startTrain:endValidation],:].reset_index().loc[:,target]\n",
    "        y_test  = final.loc[idx[reg,startTest:endTest],:].reset_index().loc[:,target]\n",
    "    \n",
    "        ppl.fit(X_train,y_train)\n",
    "        prediction = ppl.predict(X_test)\n",
    "        prediction[prediction<0] = 0\n",
    "        df_res2.loc[idx[reg,:], target] = y_test.values\n",
    "        df_res2.loc[idx[reg,:], saveDict.get(target)] = prediction\n",
    "    print reg #,' ', calcMAE(df_res)    \n",
    "df_res2.head() \n",
    "\n",
    "calcMAE(df_res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saveResults(df_res2,fName='13Aug.csv',delta=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
