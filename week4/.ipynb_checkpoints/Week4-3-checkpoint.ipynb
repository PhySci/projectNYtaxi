{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from sklearn import linear_model\n",
    "import datetime\n",
    "from itertools import product\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def regression(res, alpha = 0.1, plot = False,verbose = False):\n",
    "    X = res.drop('trip_count',axis = 1)        \n",
    "    y = res.loc[:,'trip_count'];\n",
    "    lassoReg = linear_model.Lasso(alpha = alpha, max_iter = 1e5,fit_intercept = True,random_state = 0);\n",
    "    lassoReg.fit(X,y)\n",
    "    y_pr = pd.Series(data = lassoReg.predict(X), index = res.index)\n",
    "    R = lassoReg.score(X,y);\n",
    "    print 'R factor is ', R\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize = [15,10])\n",
    "        plt.subplot(211)\n",
    "        plt.plot(y)\n",
    "        plt.plot(y_pr)\n",
    "        plt.legend(['Original data','Predicted'])\n",
    "\n",
    "        plt.subplot(212)\n",
    "        plt.plot(y-y_pr)\n",
    "        plt.legend(['Residuals'])\n",
    "        \n",
    "    return [y_pr, y-y_pr, lassoReg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRegressor(regressor, start_date = '2016-05-15 00:00:00', end_date = '2016-05-20 23:00:00'):\n",
    "    predictionStart = datetime.datetime.strptime(start_date,'%Y-%m-%d %H:%M:%S')\n",
    "    predictionEnd = datetime.datetime.strptime(end_date,'%Y-%m-%d %H:%M:%S')\n",
    "    date_index = pd.date_range(predictionStart, predictionEnd, freq='H')\n",
    "   \n",
    "    #какой-то пипец. Должен быть способ сделать это проще.\n",
    "    features = date_index.to_series().to_frame()\n",
    "    features = addFeatures(features,verbose = True)\n",
    "    features = features.drop(0,axis = 1)\n",
    "    exog = regressor.predict(features)\n",
    "    #print \n",
    "    #exog = np.expand_dims(,axis = 1)\n",
    "    #print exog\n",
    "    return pd.Series(exog,index = date_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addFeatures(res, Kw = 6, Ka = 3,verbose = False):    \n",
    "    # add linear feature\n",
    "    res = res.assign(hours = (res.index - datetime.datetime(2014,1,1,0,0,0))/np.timedelta64(1, 'h'))\n",
    "    \n",
    "    # добавляем гармонические фичи\n",
    "    for ind in range(1,Kw+1):\n",
    "        res['weekCos'+str(ind)]= np.cos(np.pi*res.hours*ind/168);\n",
    "        res['weekSin'+str(ind)]= np.sin(np.pi*res.hours*ind/168);\n",
    "    for ind in range(1,Ka+1):\n",
    "        res['yearCos'+str(ind)]= np.cos(2*np.pi*res.hours*ind/8766);\n",
    "        res['yearSin'+str(ind)]= np.sin(2*np.pi*res.hours*ind/8766);\n",
    "        \n",
    "    # добавляем dummy variables для дней недели\n",
    "    lbDays = preprocessing.LabelBinarizer()\n",
    "    lbDays.fit(list(np.arange(6)))\n",
    "    DoW = pd.DataFrame(lbDays.transform(res.index.dayofweek),columns = ['DayOfWeek_'+str(x) for x in np.arange(6)],\n",
    "                       index = res.index)      \n",
    "    res = res.merge(DoW,left_index=True,right_index=True)\n",
    " \n",
    "    # добавляем dummy variables для месяца\n",
    "    lbMonths = preprocessing.LabelBinarizer()\n",
    "    lbMonths.fit(list(np.arange(12)))\n",
    "    Months = pd.DataFrame(lbMonths.transform(res.index.month),columns = ['Month_'+str(x) for x in np.arange(12)],index = res.index)      \n",
    "    res = res.merge(Months,left_index=True,right_index=True);\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'paramsGroups.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5152c5dd46a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;31m# словарь с оптимальными параметрами для каждой группы\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mparamsGroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'paramsGroups.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\numpy\\lib\\npyio.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'paramsGroups.npy'"
     ]
    }
   ],
   "source": [
    "# id нужных регионов\n",
    "regsDf = pd.read_csv('../crowdRegs.csv',names=['id','regId']);  \n",
    "\n",
    "# временные ряды для этих регионов\n",
    "df = pd.read_pickle('../crowdRegs2.pcl')\n",
    "df.columns = regsDf.regId.values.astype('str')\n",
    "\n",
    "# словарь с группировкой рядов\n",
    "tsGroups = np.load('tsGroups.npy').item()\n",
    "\n",
    "# словарь с оптимальными параметрами для каждой группы\n",
    "paramsGroups = np.load('paramsGroups.npy').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Логика скрипта:*\n",
    "<ol>\n",
    "<li> Выбираем одну группу\n",
    "<li> В группе выбираем один ряд\n",
    "<li> По номеру группы подгружаем оптимальные параметры\n",
    "<li> Обучаем регрессор\n",
    "<li> Обучаем SARIMAX модель\n",
    "<li> Сохраняем модель (??? Может быть без данных, чтобы сэкономить место).\n",
    "<li> Делаем предсказание\n",
    "<li> Сохраняем предсказение\n",
    "<li> Идём на второй или первый шаг\n",
    "<ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# тестируем процедуру на одном ряду. Например, группа gr0, ряд 1283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group ID is gr18\n",
      "Regions is  1273\n",
      "R factor is  0.0348605313164\n",
      "Learn SARIMAX\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frodos/anaconda/lib/python2.7/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make prediction\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-1fa1a0895804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mlastLag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirstLag\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhours\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mpredicted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirstLag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlastLag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirstLag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlastLag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;31m# save results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mresDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtsId\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstartPrediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/statsmodels/base/wrapper.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/statsmodels/tsa/statespace/mlemodel.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, start, end, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m   2367\u001b[0m         \"\"\"\n\u001b[1;32m   2368\u001b[0m         \u001b[0;31m# Perform the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2369\u001b[0;31m         \u001b[0mprediction_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2370\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprediction_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicted_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/statsmodels/tsa/statespace/sarimax.pyc\u001b[0m in \u001b[0;36mget_prediction\u001b[0;34m(self, start, end, dynamic, exog, **kwargs)\u001b[0m\n\u001b[1;32m   1925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m         return super(SARIMAXResults, self).get_prediction(\n\u001b[0;32m-> 1927\u001b[0;31m             \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1928\u001b[0m         )\n\u001b[1;32m   1929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/statsmodels/tsa/statespace/mlemodel.pyc\u001b[0m in \u001b[0;36mget_prediction\u001b[0;34m(self, start, end, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m   2294\u001b[0m         \u001b[0;31m# case of npredictions = 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2295\u001b[0m         prediction_results = self.filter_results.predict(\n\u001b[0;32m-> 2296\u001b[0;31m             \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mout_of_sample\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2297\u001b[0m         )\n\u001b[1;32m   2298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/statsmodels/tsa/statespace/kalman_filter.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, start, end, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnstatic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndynamic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnforecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m         return PredictionResults(results, start, end, nstatic, ndynamic,\n",
      "\u001b[0;32m/home/frodos/anaconda/lib/python2.7/site-packages/statsmodels/tsa/statespace/kalman_filter.pyc\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, nstatic, ndynamic, nforecast, model)\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[0;31m# which dynamic computation will not be performed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnstatic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1594\u001b[0m             \u001b[0;31m# Perform dynamic prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnstatic\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mndynamic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# диапазон дат для обучения\n",
    "startFit = '2016-01-01 0:0:0'\n",
    "endFit = '2016-04-30 23:59:59'\n",
    "\n",
    "# диапазон дат для предсказания\n",
    "startPrediction = '2016-01-01 00:00:00'\n",
    "endPrediction = '2016-05-30 00:00:00'\n",
    "predictionRange = pd.date_range(startPrediction, endPrediction, freq='H')\n",
    "\n",
    "# create array to save prediction results\n",
    "mIndex = pd.MultiIndex.from_product([df.columns.values, predictionRange])\n",
    "resDf = pd.DataFrame(index = mIndex, columns = ['y','err'])\n",
    "\n",
    "\n",
    "grId = 'gr0'\n",
    "\n",
    "for grId, ts in tsGroups.iteritems():\n",
    "    print 'Group ID is', grId\n",
    "    \n",
    "    # получаем параметры SARIMAX модели\n",
    "    params = paramsGroups.get(grId)[1] \n",
    "    \n",
    "    for tsId in ts:\n",
    "        print 'Regions is ', tsId\n",
    "        # получаем временной ряд\n",
    "        ts = df.loc[startFit:endFit,tsId] #\n",
    "\n",
    "        # обучаем регрессор\n",
    "        ts = ts.to_frame(name = 'trip_count')\n",
    "        [r_pr, res, regressor] = regression(addFeatures(ts),verbose = True)\n",
    "\n",
    "        # обучаем SARIMAX модель\n",
    "        print 'Learn SARIMAX'\n",
    "        try:\n",
    "            mSARIMA=sm.tsa.statespace.SARIMAX(ts, order=[params[0], 1, params[1]],\n",
    "                                              seasonal_order=(params[2], 1, params[3], 24),\n",
    "                                              exog = r_pr, enforce_invertibility = True).fit(disp=1);\n",
    "        except Exception as inst:\n",
    "            print type(inst)     \n",
    "            print inst          \n",
    "\n",
    "        # получаем предсказания регрессора на весь диапазон дат (обучение+предсказание)\n",
    "        exog = getRegressor(regressor,startFit,endPrediction)\n",
    "        # получаем данные о поездкахы на весь диапазон дат\n",
    "        endog = df.loc[startFit:endPrediction,tsId]\n",
    "       \n",
    "        # создаём новую модель, которую будет использовать для предсказания\n",
    "        # Для чего такой финт ушами - не понимаю до сих пор\n",
    "        model_fitted = sm.tsa.statespace.SARIMAX(endog, order=[params[0], 1, params[1]],\n",
    "                                                 seasonal_order=(params[2], 1, params[3], 24),\n",
    "                                                 exog = exog).filter(mSARIMA.params)\n",
    "         \n",
    "        # проходим по всему диапазону дат предсказаний\n",
    "        print 'Make prediction'\n",
    "        for firstLag in predictionRange:\n",
    "            lastLag = firstLag+datetime.timedelta(hours = 5)\n",
    "            # prediction\n",
    "            try:\n",
    "                predicted_data = model_fitted.predict(firstLag, lastLag, dynamic=True, exog = exog[firstLag:lastLag])\n",
    "                # save results\n",
    "                resDf.loc[tsId,startPrediction].y = predicted_data\n",
    "                resDf.loc[tsId,startPrediction].err = (df.loc[startPrediction:endPrediction,tsId]-predicted_data).abs().mean()\n",
    "            except Exception as inst:\n",
    "                print 'Prediction error'\n",
    "                print inst\n",
    "                \n",
    "    # save results\n",
    "    resDf.to_pickle('predictionResults.pcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
