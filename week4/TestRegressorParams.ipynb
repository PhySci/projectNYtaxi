{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frodos/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import datetime\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def regression(res, alpha = 0.1, plot = False,verbose = False, searchBestFit = False):\n",
    "    X = res.drop('trip_count',axis = 1)        \n",
    "    y = res.loc[:,'trip_count'];\n",
    "    \n",
    "    if searchBestFit:\n",
    "        # создать словарь параметров\n",
    "        param_grid = {'alpha': [0.01,  0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6], \n",
    "                      'l1_ratio': [0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 1]}\n",
    "        # создать кросс-валидацию для временных рядов\n",
    "        tscv = model_selection.TimeSeriesSplit()\n",
    "        \n",
    "        # запустить поиск оптимальных параметров\n",
    "        regressor = linear_model.ElasticNet()\n",
    "        clf = model_selection.GridSearchCV(regressor, param_grid, n_jobs=4, cv=tscv, verbose=1)\n",
    "        clf.fit(X,y)\n",
    "        regressor = clf.best_estimator_        \n",
    "        print 'Best params is', clf.best_params_ \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        regressor = linear_model.Lasso(alpha = alpha, max_iter = 1e5,fit_intercept = True,random_state = 0);\n",
    "        regressor.fit(X,y)\n",
    "        \n",
    "    y_pr = pd.Series(data = regressor.predict(X), index = res.index)\n",
    "    R = regressor.score(X,y);\n",
    "    print 'R factor is ', R\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize = [15,10])\n",
    "        plt.subplot(211)\n",
    "        plt.plot(y)\n",
    "        plt.plot(y_pr)\n",
    "        plt.legend(['Original data','Predicted'])\n",
    "\n",
    "        plt.subplot(212)\n",
    "        plt.plot(y-y_pr)\n",
    "        plt.legend(['Residuals'])\n",
    "        \n",
    "    return [y_pr, y-y_pr, regressor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRegressor(regressor, start_date = '2016-05-15 00:00:00', end_date = '2016-05-20 23:00:00'):\n",
    "    predictionStart = datetime.datetime.strptime(start_date,'%Y-%m-%d %H:%M:%S')\n",
    "    predictionEnd = datetime.datetime.strptime(end_date,'%Y-%m-%d %H:%M:%S')\n",
    "    date_index = pd.date_range(predictionStart, predictionEnd, freq='H')\n",
    "   \n",
    "    #какой-то пипец. Должен быть способ сделать это проще.\n",
    "    features = date_index.to_series().to_frame()\n",
    "    features = addFeatures(features,verbose = True)\n",
    "    features = features.drop(0,axis = 1)\n",
    "    exog = regressor.predict(features)\n",
    "    #print \n",
    "    #exog = np.expand_dims(,axis = 1)\n",
    "    #print exog\n",
    "    return pd.Series(exog,index = date_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addFeatures(res, Kw = 6, Ka = 3,verbose = False):    \n",
    "    # add linear feature\n",
    "    res = res.assign(hours = (res.index - datetime.datetime(2014,1,1,0,0,0))/np.timedelta64(1, 'h'))\n",
    "    \n",
    "    # добавляем гармонические фичи\n",
    "    for ind in range(1,Kw+1):\n",
    "        res['weekCos'+str(ind)]= np.cos(np.pi*res.hours*ind/168);\n",
    "        res['weekSin'+str(ind)]= np.sin(np.pi*res.hours*ind/168);\n",
    "    for ind in range(1,Ka+1):\n",
    "        res['yearCos'+str(ind)]= np.cos(2*np.pi*res.hours*ind/8766);\n",
    "        res['yearSin'+str(ind)]= np.sin(2*np.pi*res.hours*ind/8766);\n",
    "        \n",
    "    # добавляем dummy variables для дней недели\n",
    "    lbDays = preprocessing.LabelBinarizer()\n",
    "    lbDays.fit(list(np.arange(6)))\n",
    "    DoW = pd.DataFrame(lbDays.transform(res.index.dayofweek),columns = ['DayOfWeek_'+str(x) for x in np.arange(6)],\n",
    "                       index = res.index)      \n",
    "    res = res.merge(DoW,left_index=True,right_index=True)\n",
    " \n",
    "    # добавляем dummy variables для месяца\n",
    "    lbMonths = preprocessing.LabelBinarizer()\n",
    "    lbMonths.fit(list(np.arange(12)))\n",
    "    Months = pd.DataFrame(lbMonths.transform(res.index.month),columns = ['Month_'+str(x) for x in np.arange(12)],index = res.index)      \n",
    "    res = res.merge(Months,left_index=True,right_index=True);\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# id нужных регионов\n",
    "regsDf = pd.read_csv('../crowdRegs.csv',names=['id','regId']);  \n",
    "\n",
    "# временные ряды для этих регионов\n",
    "df = pd.read_pickle('../loadData/crowdRegs3.pcl')\n",
    "df.columns = regsDf.regId.values.astype('str')\n",
    "\n",
    "# словарь с группировкой рядов\n",
    "tsGroups = np.load('tsGroups.npy').item()\n",
    "\n",
    "# словарь с оптимальными параметрами для каждой группы\n",
    "paramsGroups = np.load('paramsGroups.npy').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Логика скрипта:*\n",
    "<ol>\n",
    "<li> Выбираем одну группу\n",
    "<li> В группе выбираем один ряд\n",
    "<li> По номеру группы подгружаем оптимальные параметры\n",
    "<li> Обучаем регрессор\n",
    "<li> Обучаем SARIMAX модель\n",
    "<li> Сохраняем модель (??? Может быть без данных, чтобы сэкономить место).\n",
    "<li> Делаем предсказание\n",
    "<li> Сохраняем предсказение\n",
    "<li> Идём на второй или первый шаг\n",
    "<ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 63 candidates, totalling 189 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params is {'alpha': 0.1, 'l1_ratio': 0.75}\n",
      "R factor is  0.0476817220641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 182 out of 189 | elapsed:    6.1s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 189 out of 189 | elapsed:    6.2s finished\n"
     ]
    }
   ],
   "source": [
    "startFit = '2016-01-01 0:0:0'\n",
    "endFit = '2016-05-31 23:00:00'\n",
    "\n",
    "ts = df.loc[startFit:endFit,'1273'] #\n",
    "\n",
    "# обучаем регрессор\n",
    "ts = ts.to_frame(name = 'trip_count')\n",
    "[r_pr, res, regressor] = regression(addFeatures(ts),verbose = True, searchBestFit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R factor is  0.0479732808974\n"
     ]
    }
   ],
   "source": [
    "[r_pr, res, regressor] = regression(addFeatures(ts),verbose = True, searchBestFit = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# диапазон дат для обучения\n",
    "startFit = '2016-01-01 0:0:0'\n",
    "endFit = '2016-05-31 23:00:00'\n",
    "\n",
    "err = 0\n",
    "\n",
    "# диапазон дат для предсказания\n",
    "startPrediction = '2016-06-01 00:00:00'\n",
    "endPrediction   = '2016-06-30 23:00:00'\n",
    "predictionRange = pd.date_range(startPrediction, endPrediction, freq='H')\n",
    "\n",
    "# create array to save prediction results\n",
    "mIndex = pd.MultiIndex.from_product([df.columns.values, predictionRange])\n",
    "resDf = pd.DataFrame(index = mIndex, columns = ['y','err'])\n",
    "\n",
    "for grId, ts in tsGroups.iteritems():\n",
    "    print 'Group ID is', grId\n",
    "    \n",
    "    # получаем параметры SARIMAX модели\n",
    "    params = paramsGroups.get(grId)[1] \n",
    "    \n",
    "    for tsId in ts:\n",
    "        print 'Regions is ', tsId\n",
    "        # получаем временной ряд\n",
    "        ts = df.loc[startFit:endFit,tsId] #\n",
    "\n",
    "        # обучаем регрессор\n",
    "        ts = ts.to_frame(name = 'trip_count')\n",
    "        [r_pr, res, regressor] = regression(addFeatures(ts),verbose = True)\n",
    "\n",
    "        # обучаем SARIMAX модель\n",
    "        print 'Learn SARIMAX'\n",
    "        try:\n",
    "            mSARIMA=sm.tsa.statespace.SARIMAX(ts, order=[params[0], 1, params[1]],\n",
    "                                              seasonal_order=(params[2], 1, params[3], 24),\n",
    "                                              exog = r_pr, enforce_invertibility = True).fit(disp=1);\n",
    "        except Exception as inst:\n",
    "            print type(inst)     \n",
    "            print inst          \n",
    "\n",
    "        # получаем предсказания регрессора на весь диапазон дат (обучение+предсказание)\n",
    "        exog = getRegressor(regressor,startFit,endPrediction)\n",
    "        # получаем данные о поездкахы на весь диапазон дат\n",
    "        endog = df.loc[startFit:endPrediction,tsId]\n",
    "       \n",
    "        # создаём новую модель, которую будет использовать для предсказания\n",
    "        # Для чего такой финт ушами - не понимаю до сих пор\n",
    "        try:\n",
    "            model_fitted = sm.tsa.statespace.SARIMAX(endog, order=[params[0], 1, params[1]],\n",
    "                                                 seasonal_order=(params[2], 1, params[3], 24),\n",
    "                                                 exog = exog).filter(mSARIMA.params)\n",
    "        except Exception as inst:\n",
    "            print 'Can not create the model'\n",
    "            print inst\n",
    "            continue\n",
    "            \n",
    "        # проходим по всему диапазону дат предсказаний\n",
    "        print 'Make prediction'\n",
    "        for firstLag in predictionRange[:-5]:\n",
    "            lastLag = firstLag+datetime.timedelta(hours = 5)\n",
    "            # prediction\n",
    "            try:\n",
    "                predicted_data = model_fitted.predict(firstLag, lastLag, dynamic=True, exog = exog[firstLag:lastLag])\n",
    "            except Exception as inst:\n",
    "                print 'Prediction error'\n",
    "                print inst\n",
    "            else:\n",
    "                # save results\n",
    "                resDf.loc[tsId,firstLag].y = predicted_data\n",
    "                err += (df.loc[startPrediction:endPrediction,tsId]-predicted_data).abs().sum()\n",
    "                resDf.loc[tsId,firstLag].err = (df.loc[startPrediction:endPrediction,tsId]-predicted_data).abs().mean()\n",
    "                    \n",
    "    # save results\n",
    "    resDf.to_pickle('predictionResults.pcl')\n",
    "    \n",
    "print 'Total error is', err    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paramsGroups.get('gr4')[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn as skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.17.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
