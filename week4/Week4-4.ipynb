{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model, model_selection, preprocessing\n",
    "\n",
    "import datetime\n",
    "from itertools import product\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def regression(res, alpha = 0.1, plot = False,verbose = False, searchBestFit = False):\n",
    "    X = res.drop('trip_count',axis = 1)        \n",
    "    y = res.loc[:,'trip_count'];\n",
    "    \n",
    "    if searchBestFit:\n",
    "        # создать словарь параметров\n",
    "        param_grid = {'alpha': [x for x in np.linspace(10,100,10)],'l1_ratio': [0.1, 0.25, 0.4, 0.5, 0.6, 0.75, 1]}\n",
    "        # создать кросс-валидацию для временных рядов\n",
    "        tscv = model_selection.TimeSeriesSplit()\n",
    "        \n",
    "        # запустить поиск оптимальных параметров\n",
    "        regressor = linear_model.ElasticNet()\n",
    "        clf = model_selection.GridSearchCV(regressor, param_grid, n_jobs=4, cv=tscv, verbose=1)\n",
    "        clf.fit(X,y)\n",
    "        regressor = clf.best_estimator_        \n",
    "        print 'Best params is', clf.best_params_ \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        regressor = linear_model.Lasso(alpha = alpha, max_iter = 1e5,fit_intercept = True,random_state = 0);\n",
    "        regressor.fit(X,y)\n",
    "        \n",
    "    y_pr = pd.Series(data = regressor.predict(X), index = res.index)\n",
    "    R = regressor.score(X,y);\n",
    "    print 'R factor is ', R\n",
    "    \n",
    "    if plot:\n",
    "        plt.figure(figsize = [15,10])\n",
    "        plt.subplot(211)\n",
    "        plt.plot(y)\n",
    "        plt.plot(y_pr)\n",
    "        plt.legend(['Original data','Predicted'])\n",
    "\n",
    "        plt.subplot(212)\n",
    "        plt.plot(y-y_pr)\n",
    "        plt.legend(['Residuals'])\n",
    "        \n",
    "    return [y_pr, y-y_pr, regressor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getRegressor(regressor, start_date = '2016-05-15 00:00:00', end_date = '2016-05-20 23:00:00'):\n",
    "    predictionStart = datetime.datetime.strptime(start_date,'%Y-%m-%d %H:%M:%S')\n",
    "    predictionEnd = datetime.datetime.strptime(end_date,'%Y-%m-%d %H:%M:%S')\n",
    "    date_index = pd.date_range(predictionStart, predictionEnd, freq='H')\n",
    "   \n",
    "    #какой-то пипец. Должен быть способ сделать это проще.\n",
    "    features = date_index.to_series().to_frame()\n",
    "    features = addFeatures(features,verbose = True)\n",
    "    features = features.drop(0,axis = 1)\n",
    "    exog = regressor.predict(features)\n",
    "    return pd.Series(exog,index = date_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addFeatures(res, Kw = 6, Ka = 3,verbose = False):    \n",
    "    # add linear feature\n",
    "    res = res.assign(hours = (res.index - datetime.datetime(2014,1,1,0,0,0))/np.timedelta64(1, 'h'))\n",
    "    \n",
    "    # добавляем гармонические фичи\n",
    "    for ind in range(1,Kw+1):\n",
    "        res['weekCos'+str(ind)]= np.cos(np.pi*res.hours*ind/168);\n",
    "        res['weekSin'+str(ind)]= np.sin(np.pi*res.hours*ind/168);\n",
    "    for ind in range(1,Ka+1):\n",
    "        res['yearCos'+str(ind)]= np.cos(2*np.pi*res.hours*ind/8766);\n",
    "        res['yearSin'+str(ind)]= np.sin(2*np.pi*res.hours*ind/8766);\n",
    "        \n",
    "    # добавляем dummy variables для дней недели\n",
    "    lbDays = preprocessing.LabelBinarizer()\n",
    "    lbDays.fit(list(np.arange(6)))\n",
    "    DoW = pd.DataFrame(lbDays.transform(res.index.dayofweek),columns = ['DayOfWeek_'+str(x) for x in np.arange(6)],\n",
    "                       index = res.index)      \n",
    "    res = res.merge(DoW,left_index=True,right_index=True)\n",
    " \n",
    "    # добавляем dummy variables для месяца\n",
    "    lbMonths = preprocessing.LabelBinarizer()\n",
    "    lbMonths.fit(list(np.arange(12)))\n",
    "    Months = pd.DataFrame(lbMonths.transform(res.index.month),columns = ['Month_'+str(x) for x in np.arange(12)],index = res.index)      \n",
    "    res = res.merge(Months,left_index=True,right_index=True);\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findHyperParams(ts,pList = []):\n",
    "    \n",
    "    if (len(pList) ==0):\n",
    "        # create list of parameters\n",
    "        ps = range(2, 7)\n",
    "        d  = 1\n",
    "        qs = range(2, 7)\n",
    "\n",
    "        Ps = range(1, 3)\n",
    "        D  = 1\n",
    "        Qs = range(1, 3)\n",
    "\n",
    "        pList = list(product(ps, qs, Ps, Qs))\n",
    "    \n",
    "    results = []\n",
    "    best_aic = float(\"inf\")\n",
    "    \n",
    "    # add features\n",
    "    ts = addFeatures(ts, Kw = 6, Ka = 3)\n",
    "    # regression\n",
    "    [s, r, lasso] = regression(ts,verbose = True, searchBestFit = True)\n",
    "    \n",
    "    # loop over parameters' list\n",
    "    for param in pList:\n",
    "        #try except нужен, потому что на некоторых наборах параметров модель не обучается\n",
    "        print('Parameters:', param)\n",
    "        try:\n",
    "            mSARIMA=sm.tsa.statespace.SARIMAX(ts.loc[:,'trip_count'], order=[param[0], 1, param[1]],\n",
    "                                          seasonal_order=(param[2], 1, param[3], 24),exog = r).fit(disp=1);\n",
    "        #выводим параметры, на которых модель не обучается и переходим к следующему набору\n",
    "        except Exception as inst:\n",
    "            print inst           # __str__ allows args to be printed directly\n",
    "            continue\n",
    "        else:     \n",
    "            aic = mSARIMA.aic\n",
    "            print('AIC',aic) \n",
    "            #сохраняем лучшую модель, aic, параметры\n",
    "            if aic < best_aic:\n",
    "                best_model = mSARIMA\n",
    "                best_aic = aic\n",
    "                best_param = param\n",
    "            results.append([param, mSARIMA.aic])\n",
    "    return [best_aic,best_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# id нужных регионов\n",
    "regsDf = pd.read_csv('../crowdRegs.csv',names=['id','regId']);  \n",
    "\n",
    "# временные ряды для этих регионов\n",
    "df = pd.read_pickle('../loadData/crowdRegs3.pcl')\n",
    "df.columns = regsDf.regId.values.astype('str')\n",
    "\n",
    "# словарь с группировкой рядов\n",
    "tsGroups = np.load('tsGroups.npy').item()\n",
    "\n",
    "# словарь с оптимальными параметрами для каждой группы\n",
    "paramsGroups = np.load('paramsGroups.npy').item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Логика скрипта:*\n",
    "<ol>\n",
    "<li> Выбираем одну группу\n",
    "<li> В группе выбираем один ряд\n",
    "<li> По номеру группы подгружаем оптимальные параметры\n",
    "<li> Обучаем регрессор\n",
    "<li> Обучаем SARIMAX модель\n",
    "<li> Сохраняем модель (??? Может быть без данных, чтобы сэкономить место).\n",
    "<li> Делаем предсказание\n",
    "<li> Сохраняем предсказение\n",
    "<li> Идём на второй или первый шаг\n",
    "<ol>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# диапазон дат для обучения\n",
    "startFit = '2016-01-01 0:0:0'\n",
    "endFit = '2016-04-30 23:00:00'\n",
    "\n",
    "err = 0\n",
    "\n",
    "# диапазон дат для предсказания\n",
    "startPrediction = '2016-05-01 00:00:00'\n",
    "endPrediction = '2016-05-31 23:00:00'\n",
    "predictionRange = pd.date_range(startPrediction, endPrediction, freq='H')\n",
    "\n",
    "# create array to save prediction results\n",
    "mIndex = pd.MultiIndex.from_product([df.columns.values, predictionRange])\n",
    "resDf = pd.DataFrame(index = mIndex, columns = ['y','err'])\n",
    "\n",
    "for grId, ts in tsGroups.iteritems():\n",
    "    print 'Group ID is', grId\n",
    "    \n",
    "    # получаем параметры SARIMAX модели\n",
    "    params = paramsGroups.get(grId)[1] \n",
    "    \n",
    "    for tsId in ts:\n",
    "        print 'Regions is ', tsId\n",
    "        # получаем временной ряд\n",
    "        ts = df.loc[startFit:endFit,tsId] #\n",
    "\n",
    "        # обучаем регрессор\n",
    "        ts = ts.to_frame(name = 'trip_count')\n",
    "        [r_pr, res, regressor] = regression(addFeatures(ts),verbose = True)\n",
    "\n",
    "        # обучаем SARIMAX модель\n",
    "        print 'Learn SARIMAX'\n",
    "        try:\n",
    "            mSARIMA=sm.tsa.statespace.SARIMAX(ts, order=[params[0], 2, params[1]],\n",
    "                                              seasonal_order=(params[2], 1, params[3], 24),\n",
    "                                              exog = r_pr, enforce_invertibility = True).fit(disp=1);\n",
    "        except Exception as inst:\n",
    "            print type(inst)     \n",
    "            print inst          \n",
    "\n",
    "        # получаем предсказания регрессора на весь диапазон дат (обучение+предсказание)\n",
    "        exog = getRegressor(regressor,startFit,endPrediction)\n",
    "        # получаем данные о поездкахы на весь диапазон дат\n",
    "        endog = df.loc[startFit:endPrediction,tsId]\n",
    "       \n",
    "        # создаём новую модель, которую будет использовать для предсказания\n",
    "        # Для чего такой финт ушами - не понимаю до сих пор\n",
    "        try:\n",
    "            model_fitted = sm.tsa.statespace.SARIMAX(endog, order=[params[0], 1, params[1]],\n",
    "                                                 seasonal_order=(params[2], 1, params[3], 24),\n",
    "                                                 exog = exog).filter(mSARIMA.params)\n",
    "        except Exception as inst:\n",
    "            print 'Can not create the model'\n",
    "            print inst\n",
    "            continue\n",
    "            \n",
    "        # проходим по всему диапазону дат предсказаний\n",
    "        print 'Make prediction'\n",
    "        for firstLag in predictionRange[:-5]:\n",
    "            lastLag = firstLag+datetime.timedelta(hours = 5)\n",
    "            # prediction\n",
    "            try:\n",
    "                predicted_data = model_fitted.predict(firstLag, lastLag, dynamic=True, exog = exog[firstLag:lastLag])\n",
    "            except Exception as inst:\n",
    "                print 'Prediction error'\n",
    "                print inst\n",
    "            else:\n",
    "                # save results\n",
    "                #resDf.loc[tsId,firstLag].y = predicted_data\n",
    "                err += (df.loc[startPrediction:endPrediction,tsId]-predicted_data).abs().sum()\n",
    "                #resDf.loc[tsId,firstLag].err = (df.loc[startPrediction:endPrediction,tsId]-predicted_data).abs().mean()\n",
    "                    \n",
    "    # save results\n",
    "    #resDf.to_pickle('predictionResults.pcl')\n",
    "    \n",
    "print 'Total error is', err    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resDf = pd.read_pickle('predictionResults.pcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# выберу настроечные ряды руками\n",
    "fitSeries = {'gr18':'1274','gr19':'1684','gr10':'1333','gr11':'1075','gr12':'2118','gr13':'1387','gr14':'1384','gr15':'1174'}\n",
    "fitSeries.update({'gr16':'1483','gr17':'1282','gr21':'1184','gr20':'1131','gr23':'1332','gr22':'1580','gr6':'1177','gr7':'1388'})\n",
    "fitSeries.update({'gr4':'1128','gr2':'1234','gr3':'1231','gr0':'1286','gr1':'1125','gr8':'1181','gr9':'1532'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# подбираем параметры для группы 'gr2'\n",
    "startDate = '2016-01-01 0:0:0'\n",
    "endDate = '2016-04-30 23:59:59'\n",
    "\n",
    "grName = 'gr2'\n",
    "newParams = findHyperParams(df.loc[startDate:endDate,fitSeries.get(grName)].to_frame(name = 'trip_count'))\n",
    "paramsGroups.update({grName:newParams})\n",
    "np.save('paramsGroups.npy', paramsGroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# диапазон дат для обучения\n",
    "startFit = '2015-01-01 0:0:0'\n",
    "endFit = '2016-05-31 23:00:00'\n",
    "\n",
    "err = 0\n",
    "\n",
    "# диапазон дат для предсказания\n",
    "startPrediction = '2016-05-31 18:00:00'\n",
    "endPrediction   = '2016-06-30 23:00:00'\n",
    "predictionRange = pd.date_range(startPrediction, endPrediction, freq='H')\n",
    "\n",
    "# словарь с оптимальными параметрами для каждой группы\n",
    "#paramsGroups = np.load('paramsGroups.npy').item()\n",
    "\n",
    "# create array to save prediction results\n",
    "mIndex = pd.MultiIndex.from_product([df.columns.values, predictionRange])\n",
    "resDf = pd.DataFrame(index = mIndex, columns = ['y','err'])\n",
    "# load data\n",
    "#resDf = pd.read_pickle('predictionResults5.pcl')\n",
    "recalcRegions = [1272,1377]\n",
    "\n",
    "\n",
    "for grId, ts in tsGroups.iteritems(): #{k: v for k, v in tsGroups.iteritems() if k in recalcGroups}.iteritems():\n",
    "    \n",
    "    print 'Group ID is', grId\n",
    "    \n",
    "    # получаем параметры SARIMAX модели\n",
    "    params = paramsGroups.get(grId)[1] \n",
    "        \n",
    "    for tsId in ts:\n",
    "        \n",
    "        # \n",
    "        #if ~np.isnan(resDf.loc[tsId,'2016-06-15'].err):\n",
    "        #    print 'Already done!'\n",
    "        #    continue\n",
    "        \n",
    "        #if tsId not in ['1272', '1377']:\n",
    "        #    continue\n",
    "    \n",
    "        print 'Regions is ', tsId\n",
    "        # получаем временной ряд\n",
    "        ts = df.loc[startFit:endFit,tsId] #\n",
    "\n",
    "        # обучаем регрессор\n",
    "        ts = ts.to_frame(name = 'trip_count')\n",
    "        [r_pr, res, regressor] = regression(addFeatures(ts),verbose = True, searchBestFit = True)\n",
    "\n",
    "        # обучаем SARIMAX модель\n",
    "        print 'Learn SARIMAX'\n",
    "        try:\n",
    "            mSARIMA=sm.tsa.statespace.SARIMAX(ts, order=[params[0]+1, 2, params[1]+1],\n",
    "                                              seasonal_order=(params[2]+1, 1, params[3]+1, 24),\n",
    "                                              exog = r_pr).fit(disp=1);\n",
    "        except Exception as inst:\n",
    "            print type(inst)     \n",
    "            print inst          \n",
    "\n",
    "        # получаем предсказания регрессора на весь диапазон дат (обучение+предсказание)\n",
    "        exog = getRegressor(regressor,startFit,endPrediction)\n",
    "        # получаем данные о поездкахы на весь диапазон дат\n",
    "        endog = df.loc[startFit:endPrediction,tsId]\n",
    "       \n",
    "        # создаём новую модель, которую будет использовать для предсказания\n",
    "        # Для чего такой финт ушами - не понимаю до сих пор\n",
    "        try:\n",
    "            model_fitted = sm.tsa.statespace.SARIMAX(endog, order=[params[0]+1, 2, params[1]+1],\n",
    "                                                 seasonal_order=(params[2]+1, 1, params[3]+1, 24),\n",
    "                                                 exog = exog).filter(mSARIMA.params)\n",
    "        except Exception as inst:\n",
    "            print 'Can not create the model'\n",
    "            print inst\n",
    "            continue\n",
    "        else:    \n",
    "            # проходим по всему диапазону дат предсказаний\n",
    "            print 'Make prediction'\n",
    "            for firstLag in predictionRange:\n",
    "                lastLag = firstLag+datetime.timedelta(hours = 5)\n",
    "                # prediction\n",
    "                try:\n",
    "                    predicted_data = model_fitted.predict(firstLag, lastLag, dynamic=True, exog = exog[firstLag:lastLag])\n",
    "                except Exception as inst:\n",
    "                    print 'Prediction error'\n",
    "                    print inst\n",
    "                else:\n",
    "                    # save results\n",
    "                    resDf.loc[tsId,firstLag].y = predicted_data\n",
    "                    err += (df.loc[startPrediction:endPrediction,tsId]-predicted_data).abs().sum()\n",
    "                    resDf.loc[tsId,firstLag].err = (df.loc[startPrediction:endPrediction,tsId]-predicted_data).abs().mean()\n",
    "\n",
    "            # save results\n",
    "            resDf.to_pickle('predictionResults5.pcl')\n",
    "    \n",
    "print 'Total error is', err    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resDf = pd.read_pickle('predictionResults7.pcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveResults(df, fName):\n",
    "    \"\"\"\n",
    "    Save dataframe df to file fName\n",
    "    \"\"\"\n",
    "    f = open(fName, 'w')\n",
    "    for ts in df.index.levels[0]:\n",
    "        for lag in df.index.levels[1][6:-5]:\n",
    "            for i in np.arange(6):\n",
    "                try:\n",
    "                    historyStart = lag - datetime.timedelta(hours = 1)\n",
    "                    res = df.loc[ts,lag].y[i]\n",
    "                    if res<0:\n",
    "                        res = 0\n",
    "                    s =  str(ts)+'_'+datetime.datetime.strftime(historyStart, \"%Y-%m-%d\") +'_'+ str(historyStart.hour)+'_'+str(i+1)+','+str(res)+'\\n'\n",
    "                except Exception as ins:\n",
    "                    print lag, ts, i\n",
    "                    print ins\n",
    "                else:\n",
    "                    f.write(s)\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "#resDf = pd.read_pickle('predictionResults6.pcl')\n",
    "saveResults(resDf,'m9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2014-01-01     69.208333\n",
       "2014-01-02     55.083333\n",
       "2014-01-03     28.791667\n",
       "2014-01-04     52.125000\n",
       "2014-01-05     37.291667\n",
       "2014-01-06     52.041667\n",
       "2014-01-07     63.208333\n",
       "2014-01-08     66.583333\n",
       "2014-01-09     69.958333\n",
       "2014-01-10     69.083333\n",
       "2014-01-11     44.833333\n",
       "2014-01-12     47.958333\n",
       "2014-01-13     55.458333\n",
       "2014-01-14     62.416667\n",
       "2014-01-15     70.916667\n",
       "2014-01-16     79.125000\n",
       "2014-01-17     69.833333\n",
       "2014-01-18     53.458333\n",
       "2014-01-19     51.291667\n",
       "2014-01-20     48.250000\n",
       "2014-01-21     33.583333\n",
       "2014-01-22     48.708333\n",
       "2014-01-23     69.875000\n",
       "2014-01-24     66.708333\n",
       "2014-01-25     52.625000\n",
       "2014-01-26     46.458333\n",
       "2014-01-27     60.625000\n",
       "2014-01-28     69.500000\n",
       "2014-01-29     70.583333\n",
       "2014-01-30     69.000000\n",
       "                 ...    \n",
       "2016-06-01     63.500000\n",
       "2016-06-02     68.041667\n",
       "2016-06-03     70.250000\n",
       "2016-06-04     87.625000\n",
       "2016-06-05     51.750000\n",
       "2016-06-06     69.416667\n",
       "2016-06-07     68.500000\n",
       "2016-06-08     65.291667\n",
       "2016-06-09     72.625000\n",
       "2016-06-10     83.416667\n",
       "2016-06-11     77.791667\n",
       "2016-06-12     62.208333\n",
       "2016-06-13     58.333333\n",
       "2016-06-14     66.125000\n",
       "2016-06-15     75.083333\n",
       "2016-06-16     72.458333\n",
       "2016-06-17     69.291667\n",
       "2016-06-18     91.625000\n",
       "2016-06-19     69.791667\n",
       "2016-06-20     61.541667\n",
       "2016-06-21     67.541667\n",
       "2016-06-22     71.041667\n",
       "2016-06-23     79.208333\n",
       "2016-06-24     81.708333\n",
       "2016-06-25    101.333333\n",
       "2016-06-26     75.291667\n",
       "2016-06-27     71.541667\n",
       "2016-06-28     64.166667\n",
       "2016-06-29     74.500000\n",
       "2016-06-30     70.000000\n",
       "Freq: D, Name: 1075, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,'1075'].resample('1D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
